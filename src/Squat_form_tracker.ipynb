{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80c6cc9d-aec8-4b96-86e8-6a1f4fa51272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ultralytics\n",
      "  Using cached ultralytics-8.3.117-py3-none-any.whl.metadata (37 kB)\n",
      "Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in c:\\users\\kassimi\\anaconda3\\lib\\site-packages (from ultralytics) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\kassimi\\anaconda3\\lib\\site-packages (from ultralytics) (3.9.2)\n",
      "Collecting opencv-python>=4.6.0 (from ultralytics)\n",
      "  Using cached opencv_python-4.11.0.86-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\kassimi\\anaconda3\\lib\\site-packages (from ultralytics) (10.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\kassimi\\anaconda3\\lib\\site-packages (from ultralytics) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\kassimi\\anaconda3\\lib\\site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\kassimi\\anaconda3\\lib\\site-packages (from ultralytics) (1.13.1)\n",
      "Collecting torch>=1.8.0 (from ultralytics)\n",
      "  Using cached torch-2.7.0-cp312-cp312-win_amd64.whl.metadata (29 kB)\n",
      "Collecting torchvision>=0.9.0 (from ultralytics)\n",
      "  Using cached torchvision-0.22.0-cp312-cp312-win_amd64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\kassimi\\anaconda3\\lib\\site-packages (from ultralytics) (4.66.5)\n",
      "Requirement already satisfied: psutil in c:\\users\\kassimi\\anaconda3\\lib\\site-packages (from ultralytics) (5.9.0)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\users\\kassimi\\anaconda3\\lib\\site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\kassimi\\anaconda3\\lib\\site-packages (from ultralytics) (2.2.2)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\users\\kassimi\\anaconda3\\lib\\site-packages (from ultralytics) (0.13.2)\n",
      "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
      "  Using cached ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\kassimi\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\kassimi\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\kassimi\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\kassimi\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\kassimi\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\kassimi\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\kassimi\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\kassimi\\anaconda3\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\kassimi\\anaconda3\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kassimi\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kassimi\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kassimi\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kassimi\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n",
      "Requirement already satisfied: filelock in c:\\users\\kassimi\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\kassimi\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.11.0)\n",
      "Collecting sympy>=1.13.3 (from torch>=1.8.0->ultralytics)\n",
      "  Using cached sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: networkx in c:\\users\\kassimi\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\kassimi\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\kassimi\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\kassimi\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (75.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\kassimi\\anaconda3\\lib\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kassimi\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\kassimi\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\kassimi\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\n",
      "Using cached ultralytics-8.3.117-py3-none-any.whl (984 kB)\n",
      "Using cached opencv_python-4.11.0.86-cp37-abi3-win_amd64.whl (39.5 MB)\n",
      "Downloading torch-2.7.0-cp312-cp312-win_amd64.whl (212.5 MB)\n",
      "   ---------------------------------------- 0.0/212.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/212.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/212.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/212.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/212.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/212.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/212.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/212.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.5/212.5 MB 262.1 kB/s eta 0:13:29\n",
      "   ---------------------------------------- 0.5/212.5 MB 262.1 kB/s eta 0:13:29\n",
      "   ---------------------------------------- 0.5/212.5 MB 262.1 kB/s eta 0:13:29\n",
      "   ---------------------------------------- 0.5/212.5 MB 262.1 kB/s eta 0:13:29\n",
      "   ---------------------------------------- 0.5/212.5 MB 262.1 kB/s eta 0:13:29\n",
      "   ---------------------------------------- 0.5/212.5 MB 262.1 kB/s eta 0:13:29\n",
      "   ---------------------------------------- 0.5/212.5 MB 262.1 kB/s eta 0:13:29\n",
      "   ---------------------------------------- 0.5/212.5 MB 262.1 kB/s eta 0:13:29\n",
      "   ---------------------------------------- 0.5/212.5 MB 262.1 kB/s eta 0:13:29\n",
      "   ---------------------------------------- 0.8/212.5 MB 186.4 kB/s eta 0:18:56\n",
      "   ---------------------------------------- 0.8/212.5 MB 186.4 kB/s eta 0:18:56\n",
      "   ---------------------------------------- 0.8/212.5 MB 186.4 kB/s eta 0:18:56\n",
      "   ---------------------------------------- 0.8/212.5 MB 186.4 kB/s eta 0:18:56\n",
      "   ---------------------------------------- 0.8/212.5 MB 186.4 kB/s eta 0:18:56\n",
      "   ---------------------------------------- 0.8/212.5 MB 186.4 kB/s eta 0:18:56\n",
      "   ---------------------------------------- 0.8/212.5 MB 186.4 kB/s eta 0:18:56\n",
      "   ---------------------------------------- 0.8/212.5 MB 186.4 kB/s eta 0:18:56\n",
      "   ---------------------------------------- 0.8/212.5 MB 186.4 kB/s eta 0:18:56\n",
      "   ---------------------------------------- 0.8/212.5 MB 186.4 kB/s eta 0:18:56\n",
      "   ---------------------------------------- 0.8/212.5 MB 186.4 kB/s eta 0:18:56\n",
      "   ---------------------------------------- 0.8/212.5 MB 186.4 kB/s eta 0:18:56\n",
      "   ---------------------------------------- 0.8/212.5 MB 186.4 kB/s eta 0:18:56\n",
      "   ---------------------------------------- 0.8/212.5 MB 186.4 kB/s eta 0:18:56\n",
      "   ---------------------------------------- 0.8/212.5 MB 186.4 kB/s eta 0:18:56\n",
      "   ---------------------------------------- 0.8/212.5 MB 186.4 kB/s eta 0:18:56\n",
      "   ---------------------------------------- 0.8/212.5 MB 186.4 kB/s eta 0:18:56\n",
      "   ---------------------------------------- 0.8/212.5 MB 186.4 kB/s eta 0:18:56\n",
      "   ---------------------------------------- 0.8/212.5 MB 186.4 kB/s eta 0:18:56\n",
      "   ---------------------------------------- 0.8/212.5 MB 186.4 kB/s eta 0:18:56\n",
      "   ---------------------------------------- 0.8/212.5 MB 186.4 kB/s eta 0:18:56\n",
      "   ---------------------------------------- 0.8/212.5 MB 186.4 kB/s eta 0:18:56\n",
      "   ---------------------------------------- 0.8/212.5 MB 186.4 kB/s eta 0:18:56\n",
      "   ---------------------------------------- 0.8/212.5 MB 186.4 kB/s eta 0:18:56\n",
      "   ---------------------------------------- 0.8/212.5 MB 186.4 kB/s eta 0:18:56\n",
      "   ---------------------------------------- 0.8/212.5 MB 186.4 kB/s eta 0:18:56\n",
      "   ---------------------------------------- 0.8/212.5 MB 186.4 kB/s eta 0:18:56\n",
      "   ---------------------------------------- 0.8/212.5 MB 186.4 kB/s eta 0:18:56\n",
      "   ---------------------------------------- 0.8/212.5 MB 186.4 kB/s eta 0:18:56\n",
      "   ---------------------------------------- 1.0/212.5 MB 87.8 kB/s eta 0:40:08\n",
      "   ---------------------------------------- 1.0/212.5 MB 87.8 kB/s eta 0:40:08\n",
      "   ---------------------------------------- 1.0/212.5 MB 87.8 kB/s eta 0:40:08\n",
      "   ---------------------------------------- 1.0/212.5 MB 87.8 kB/s eta 0:40:08\n",
      "   ---------------------------------------- 1.0/212.5 MB 87.8 kB/s eta 0:40:08\n",
      "   ---------------------------------------- 1.0/212.5 MB 87.8 kB/s eta 0:40:08\n",
      "   ---------------------------------------- 1.0/212.5 MB 87.8 kB/s eta 0:40:08\n",
      "   ---------------------------------------- 1.0/212.5 MB 87.8 kB/s eta 0:40:08\n",
      "   ---------------------------------------- 1.0/212.5 MB 87.8 kB/s eta 0:40:08\n",
      "   ---------------------------------------- 1.0/212.5 MB 87.8 kB/s eta 0:40:08\n",
      "   ---------------------------------------- 1.0/212.5 MB 87.8 kB/s eta 0:40:08\n",
      "   ---------------------------------------- 1.0/212.5 MB 87.8 kB/s eta 0:40:08\n",
      "   ---------------------------------------- 1.0/212.5 MB 87.8 kB/s eta 0:40:08\n",
      "   ---------------------------------------- 1.0/212.5 MB 87.8 kB/s eta 0:40:08\n",
      "   ---------------------------------------- 1.0/212.5 MB 87.8 kB/s eta 0:40:08\n",
      "   ---------------------------------------- 1.0/212.5 MB 87.8 kB/s eta 0:40:08\n",
      "   ---------------------------------------- 1.0/212.5 MB 87.8 kB/s eta 0:40:08\n",
      "   ---------------------------------------- 1.0/212.5 MB 87.8 kB/s eta 0:40:08\n",
      "   ---------------------------------------- 1.0/212.5 MB 87.8 kB/s eta 0:40:08\n",
      "   ---------------------------------------- 1.0/212.5 MB 87.8 kB/s eta 0:40:08\n",
      "   ---------------------------------------- 1.0/212.5 MB 87.8 kB/s eta 0:40:08\n",
      "   ---------------------------------------- 1.0/212.5 MB 87.8 kB/s eta 0:40:08\n",
      "   ---------------------------------------- 1.0/212.5 MB 87.8 kB/s eta 0:40:08\n",
      "   ---------------------------------------- 1.0/212.5 MB 87.8 kB/s eta 0:40:08\n",
      "   ---------------------------------------- 1.0/212.5 MB 87.8 kB/s eta 0:40:08\n",
      "   ---------------------------------------- 1.0/212.5 MB 87.8 kB/s eta 0:40:08\n",
      "   ---------------------------------------- 1.0/212.5 MB 87.8 kB/s eta 0:40:08\n",
      "   ---------------------------------------- 1.0/212.5 MB 87.8 kB/s eta 0:40:08\n",
      "   ---------------------------------------- 1.0/212.5 MB 87.8 kB/s eta 0:40:08\n",
      "   ---------------------------------------- 1.0/212.5 MB 87.8 kB/s eta 0:40:08\n",
      "   ---------------------------------------- 1.0/212.5 MB 87.8 kB/s eta 0:40:08\n",
      "   ---------------------------------------- 1.0/212.5 MB 87.8 kB/s eta 0:40:08\n",
      "   ---------------------------------------- 1.0/212.5 MB 87.8 kB/s eta 0:40:08\n",
      "   ---------------------------------------- 1.0/212.5 MB 87.8 kB/s eta 0:40:08\n",
      "   ---------------------------------------- 1.3/212.5 MB 65.6 kB/s eta 0:53:39\n",
      "   ---------------------------------------- 1.3/212.5 MB 65.6 kB/s eta 0:53:39\n",
      "   ---------------------------------------- 1.3/212.5 MB 65.6 kB/s eta 0:53:39\n",
      "   ---------------------------------------- 1.3/212.5 MB 65.6 kB/s eta 0:53:39\n",
      "   ---------------------------------------- 1.3/212.5 MB 65.6 kB/s eta 0:53:39\n",
      "   ---------------------------------------- 1.3/212.5 MB 65.6 kB/s eta 0:53:39\n",
      "   ---------------------------------------- 1.3/212.5 MB 65.6 kB/s eta 0:53:39\n",
      "   ---------------------------------------- 1.3/212.5 MB 65.6 kB/s eta 0:53:39\n",
      "   ---------------------------------------- 1.3/212.5 MB 65.6 kB/s eta 0:53:39\n",
      "   ---------------------------------------- 1.3/212.5 MB 65.6 kB/s eta 0:53:39\n",
      "   ---------------------------------------- 1.3/212.5 MB 65.6 kB/s eta 0:53:39\n",
      "   ---------------------------------------- 1.3/212.5 MB 65.6 kB/s eta 0:53:39\n",
      "   ---------------------------------------- 1.3/212.5 MB 65.6 kB/s eta 0:53:39\n",
      "   ---------------------------------------- 1.3/212.5 MB 65.6 kB/s eta 0:53:39\n",
      "   ---------------------------------------- 1.3/212.5 MB 65.6 kB/s eta 0:53:39\n",
      "   ---------------------------------------- 1.3/212.5 MB 65.6 kB/s eta 0:53:39\n",
      "   ---------------------------------------- 1.3/212.5 MB 65.6 kB/s eta 0:53:39\n",
      "   ---------------------------------------- 1.3/212.5 MB 65.6 kB/s eta 0:53:39\n",
      "   ---------------------------------------- 1.3/212.5 MB 65.6 kB/s eta 0:53:39\n",
      "   ---------------------------------------- 1.3/212.5 MB 65.6 kB/s eta 0:53:39\n",
      "   ---------------------------------------- 1.3/212.5 MB 65.6 kB/s eta 0:53:39\n",
      "   ---------------------------------------- 1.3/212.5 MB 65.6 kB/s eta 0:53:39\n",
      "   ---------------------------------------- 1.3/212.5 MB 65.6 kB/s eta 0:53:39\n",
      "   ---------------------------------------- 1.6/212.5 MB 63.1 kB/s eta 0:55:44\n",
      "   ---------------------------------------- 1.6/212.5 MB 63.1 kB/s eta 0:55:44\n",
      "   ---------------------------------------- 1.6/212.5 MB 63.1 kB/s eta 0:55:44\n",
      "   ---------------------------------------- 1.6/212.5 MB 63.1 kB/s eta 0:55:44\n",
      "   ---------------------------------------- 1.6/212.5 MB 63.1 kB/s eta 0:55:44\n",
      "   ---------------------------------------- 1.6/212.5 MB 63.1 kB/s eta 0:55:44\n",
      "   ---------------------------------------- 1.6/212.5 MB 63.1 kB/s eta 0:55:44\n",
      "   ---------------------------------------- 1.6/212.5 MB 63.1 kB/s eta 0:55:44\n",
      "   ---------------------------------------- 1.6/212.5 MB 63.1 kB/s eta 0:55:44\n",
      "   ---------------------------------------- 1.6/212.5 MB 63.1 kB/s eta 0:55:44\n",
      "   ---------------------------------------- 1.6/212.5 MB 63.1 kB/s eta 0:55:44\n",
      "   ---------------------------------------- 1.6/212.5 MB 63.1 kB/s eta 0:55:44\n",
      "   ---------------------------------------- 1.6/212.5 MB 63.1 kB/s eta 0:55:44\n",
      "   ---------------------------------------- 1.6/212.5 MB 63.1 kB/s eta 0:55:44\n",
      "   ---------------------------------------- 1.6/212.5 MB 63.1 kB/s eta 0:55:44\n",
      "   ---------------------------------------- 1.6/212.5 MB 63.1 kB/s eta 0:55:44\n",
      "   ---------------------------------------- 1.6/212.5 MB 63.1 kB/s eta 0:55:44\n",
      "   ---------------------------------------- 1.8/212.5 MB 64.4 kB/s eta 0:54:33\n",
      "   ---------------------------------------- 1.8/212.5 MB 64.4 kB/s eta 0:54:33\n",
      "   ---------------------------------------- 1.8/212.5 MB 64.4 kB/s eta 0:54:33\n",
      "   ---------------------------------------- 1.8/212.5 MB 64.4 kB/s eta 0:54:33\n",
      "   ---------------------------------------- 1.8/212.5 MB 64.4 kB/s eta 0:54:33\n",
      "   ---------------------------------------- 1.8/212.5 MB 64.4 kB/s eta 0:54:33\n",
      "   ---------------------------------------- 1.8/212.5 MB 64.4 kB/s eta 0:54:33\n",
      "   ---------------------------------------- 1.8/212.5 MB 64.4 kB/s eta 0:54:33\n",
      "   ---------------------------------------- 1.8/212.5 MB 64.4 kB/s eta 0:54:33\n",
      "   ---------------------------------------- 1.8/212.5 MB 64.4 kB/s eta 0:54:33\n",
      "   ---------------------------------------- 1.8/212.5 MB 64.4 kB/s eta 0:54:33\n",
      "   ---------------------------------------- 1.8/212.5 MB 64.4 kB/s eta 0:54:33\n",
      "   ---------------------------------------- 1.8/212.5 MB 64.4 kB/s eta 0:54:33\n",
      "   ---------------------------------------- 1.8/212.5 MB 64.4 kB/s eta 0:54:33\n",
      "   ---------------------------------------- 1.8/212.5 MB 64.4 kB/s eta 0:54:33\n",
      "   ---------------------------------------- 1.8/212.5 MB 64.4 kB/s eta 0:54:33\n",
      "   ---------------------------------------- 1.8/212.5 MB 64.4 kB/s eta 0:54:33\n",
      "   ---------------------------------------- 1.8/212.5 MB 64.4 kB/s eta 0:54:33\n",
      "   ---------------------------------------- 1.8/212.5 MB 64.4 kB/s eta 0:54:33\n",
      "   ---------------------------------------- 1.8/212.5 MB 64.4 kB/s eta 0:54:33\n",
      "   ---------------------------------------- 2.1/212.5 MB 63.7 kB/s eta 0:55:06\n",
      "   ---------------------------------------- 2.1/212.5 MB 63.7 kB/s eta 0:55:06\n",
      "   ---------------------------------------- 2.1/212.5 MB 63.7 kB/s eta 0:55:06\n",
      "   ---------------------------------------- 2.1/212.5 MB 63.7 kB/s eta 0:55:06\n",
      "   ---------------------------------------- 2.1/212.5 MB 63.7 kB/s eta 0:55:06\n",
      "   ---------------------------------------- 2.1/212.5 MB 63.7 kB/s eta 0:55:06\n",
      "   ---------------------------------------- 2.1/212.5 MB 63.7 kB/s eta 0:55:06\n",
      "   ---------------------------------------- 2.1/212.5 MB 63.7 kB/s eta 0:55:06\n",
      "   ---------------------------------------- 2.1/212.5 MB 63.7 kB/s eta 0:55:06\n",
      "   ---------------------------------------- 2.1/212.5 MB 63.7 kB/s eta 0:55:06\n",
      "   ---------------------------------------- 2.1/212.5 MB 63.7 kB/s eta 0:55:06\n",
      "   ---------------------------------------- 2.1/212.5 MB 63.7 kB/s eta 0:55:06\n",
      "   ---------------------------------------- 2.1/212.5 MB 63.7 kB/s eta 0:55:06\n",
      "   ---------------------------------------- 2.1/212.5 MB 63.7 kB/s eta 0:55:06\n",
      "   ---------------------------------------- 2.1/212.5 MB 63.7 kB/s eta 0:55:06\n",
      "   ---------------------------------------- 2.1/212.5 MB 63.7 kB/s eta 0:55:06\n",
      "   ---------------------------------------- 2.1/212.5 MB 63.7 kB/s eta 0:55:06\n",
      "   ---------------------------------------- 2.1/212.5 MB 63.7 kB/s eta 0:55:06\n",
      "   ---------------------------------------- 2.1/212.5 MB 63.7 kB/s eta 0:55:06\n",
      "   ---------------------------------------- 2.4/212.5 MB 52.6 kB/s eta 1:06:32\n",
      "   ---------------------------------------- 2.4/212.5 MB 52.6 kB/s eta 1:06:32\n",
      "   ---------------------------------------- 2.4/212.5 MB 52.6 kB/s eta 1:06:32\n",
      "   ---------------------------------------- 2.4/212.5 MB 52.6 kB/s eta 1:06:32\n",
      "   ---------------------------------------- 2.4/212.5 MB 52.6 kB/s eta 1:06:32\n",
      "   ---------------------------------------- 2.4/212.5 MB 52.6 kB/s eta 1:06:32\n",
      "   ---------------------------------------- 2.4/212.5 MB 52.6 kB/s eta 1:06:32\n",
      "   ---------------------------------------- 2.4/212.5 MB 52.6 kB/s eta 1:06:32\n",
      "   ---------------------------------------- 2.4/212.5 MB 52.6 kB/s eta 1:06:32\n",
      "   ---------------------------------------- 2.4/212.5 MB 52.6 kB/s eta 1:06:32\n",
      "   ---------------------------------------- 2.4/212.5 MB 52.6 kB/s eta 1:06:32\n",
      "   ---------------------------------------- 2.4/212.5 MB 52.6 kB/s eta 1:06:32\n",
      "   ---------------------------------------- 2.4/212.5 MB 52.6 kB/s eta 1:06:32\n",
      "   ---------------------------------------- 2.4/212.5 MB 52.6 kB/s eta 1:06:32\n",
      "   ---------------------------------------- 2.4/212.5 MB 52.6 kB/s eta 1:06:32\n",
      "   ---------------------------------------- 2.4/212.5 MB 52.6 kB/s eta 1:06:32\n",
      "   ---------------------------------------- 2.4/212.5 MB 52.6 kB/s eta 1:06:32\n",
      "   ---------------------------------------- 2.6/212.5 MB 57.6 kB/s eta 1:00:47\n",
      "   ---------------------------------------- 2.6/212.5 MB 57.6 kB/s eta 1:00:47\n",
      "   ---------------------------------------- 2.6/212.5 MB 57.6 kB/s eta 1:00:47\n",
      "   ---------------------------------------- 2.6/212.5 MB 57.6 kB/s eta 1:00:47\n",
      "   ---------------------------------------- 2.6/212.5 MB 57.6 kB/s eta 1:00:47\n",
      "   ---------------------------------------- 2.6/212.5 MB 57.6 kB/s eta 1:00:47\n",
      "   ---------------------------------------- 2.6/212.5 MB 57.6 kB/s eta 1:00:47\n",
      "   ---------------------------------------- 2.6/212.5 MB 57.6 kB/s eta 1:00:47\n",
      "   ---------------------------------------- 2.6/212.5 MB 57.6 kB/s eta 1:00:47\n",
      "   ---------------------------------------- 2.6/212.5 MB 57.6 kB/s eta 1:00:47\n",
      "   ---------------------------------------- 2.6/212.5 MB 57.6 kB/s eta 1:00:47\n",
      "   ---------------------------------------- 2.6/212.5 MB 57.6 kB/s eta 1:00:47\n",
      "   ---------------------------------------- 2.6/212.5 MB 57.6 kB/s eta 1:00:47\n",
      "   ---------------------------------------- 2.6/212.5 MB 57.6 kB/s eta 1:00:47\n",
      "   ---------------------------------------- 2.6/212.5 MB 57.6 kB/s eta 1:00:47\n",
      "   ---------------------------------------- 2.6/212.5 MB 57.6 kB/s eta 1:00:47\n",
      "   ---------------------------------------- 2.6/212.5 MB 57.6 kB/s eta 1:00:47\n",
      "   ---------------------------------------- 2.6/212.5 MB 57.6 kB/s eta 1:00:47\n",
      "   ---------------------------------------- 2.6/212.5 MB 57.6 kB/s eta 1:00:47\n",
      "   ---------------------------------------- 2.6/212.5 MB 57.6 kB/s eta 1:00:47\n",
      "   ---------------------------------------- 2.6/212.5 MB 57.6 kB/s eta 1:00:47\n",
      "   ---------------------------------------- 2.6/212.5 MB 57.6 kB/s eta 1:00:47\n",
      "   ---------------------------------------- 2.6/212.5 MB 57.6 kB/s eta 1:00:47\n",
      "   ---------------------------------------- 2.6/212.5 MB 57.6 kB/s eta 1:00:47\n",
      "    --------------------------------------- 2.9/212.5 MB 62.0 kB/s eta 0:56:22\n",
      "    --------------------------------------- 2.9/212.5 MB 62.0 kB/s eta 0:56:22\n",
      "    --------------------------------------- 2.9/212.5 MB 62.0 kB/s eta 0:56:22\n",
      "    --------------------------------------- 2.9/212.5 MB 62.0 kB/s eta 0:56:22\n",
      "    --------------------------------------- 2.9/212.5 MB 62.0 kB/s eta 0:56:22\n",
      "    --------------------------------------- 2.9/212.5 MB 62.0 kB/s eta 0:56:22\n",
      "    --------------------------------------- 2.9/212.5 MB 62.0 kB/s eta 0:56:22\n",
      "    --------------------------------------- 2.9/212.5 MB 62.0 kB/s eta 0:56:22\n",
      "    --------------------------------------- 2.9/212.5 MB 62.0 kB/s eta 0:56:22\n",
      "    --------------------------------------- 2.9/212.5 MB 62.0 kB/s eta 0:56:22\n",
      "    --------------------------------------- 2.9/212.5 MB 62.0 kB/s eta 0:56:22\n",
      "    --------------------------------------- 2.9/212.5 MB 62.0 kB/s eta 0:56:22\n",
      "    --------------------------------------- 2.9/212.5 MB 62.0 kB/s eta 0:56:22\n",
      "    --------------------------------------- 2.9/212.5 MB 62.0 kB/s eta 0:56:22\n",
      "    --------------------------------------- 2.9/212.5 MB 62.0 kB/s eta 0:56:22\n",
      "    --------------------------------------- 2.9/212.5 MB 62.0 kB/s eta 0:56:22\n",
      "    --------------------------------------- 2.9/212.5 MB 62.0 kB/s eta 0:56:22\n",
      "    --------------------------------------- 2.9/212.5 MB 62.0 kB/s eta 0:56:22\n",
      "    --------------------------------------- 2.9/212.5 MB 62.0 kB/s eta 0:56:22\n",
      "    --------------------------------------- 3.1/212.5 MB 62.7 kB/s eta 0:55:41\n",
      "    --------------------------------------- 3.1/212.5 MB 62.7 kB/s eta 0:55:41\n",
      "    --------------------------------------- 3.1/212.5 MB 62.7 kB/s eta 0:55:41\n",
      "    --------------------------------------- 3.1/212.5 MB 62.7 kB/s eta 0:55:41\n",
      "    --------------------------------------- 3.1/212.5 MB 62.7 kB/s eta 0:55:41\n",
      "    --------------------------------------- 3.1/212.5 MB 62.7 kB/s eta 0:55:41\n",
      "    --------------------------------------- 3.1/212.5 MB 62.7 kB/s eta 0:55:41\n",
      "    --------------------------------------- 3.1/212.5 MB 62.7 kB/s eta 0:55:41\n",
      "    --------------------------------------- 3.1/212.5 MB 62.7 kB/s eta 0:55:41\n",
      "    --------------------------------------- 3.1/212.5 MB 62.7 kB/s eta 0:55:41\n",
      "    --------------------------------------- 3.1/212.5 MB 62.7 kB/s eta 0:55:41\n",
      "    --------------------------------------- 3.1/212.5 MB 62.7 kB/s eta 0:55:41\n",
      "    --------------------------------------- 3.1/212.5 MB 62.7 kB/s eta 0:55:41\n",
      "    --------------------------------------- 3.1/212.5 MB 62.7 kB/s eta 0:55:41\n",
      "    --------------------------------------- 3.1/212.5 MB 62.7 kB/s eta 0:55:41\n",
      "    --------------------------------------- 3.1/212.5 MB 62.7 kB/s eta 0:55:41\n",
      "    --------------------------------------- 3.1/212.5 MB 62.7 kB/s eta 0:55:41\n",
      "    --------------------------------------- 3.1/212.5 MB 62.7 kB/s eta 0:55:41\n",
      "    --------------------------------------- 3.1/212.5 MB 62.7 kB/s eta 0:55:41\n",
      "    --------------------------------------- 3.1/212.5 MB 62.7 kB/s eta 0:55:41\n",
      "    --------------------------------------- 3.4/212.5 MB 63.8 kB/s eta 0:54:40\n",
      "    --------------------------------------- 3.4/212.5 MB 63.8 kB/s eta 0:54:40\n",
      "    --------------------------------------- 3.4/212.5 MB 63.8 kB/s eta 0:54:40\n",
      "    --------------------------------------- 3.4/212.5 MB 63.8 kB/s eta 0:54:40\n",
      "    --------------------------------------- 3.4/212.5 MB 63.8 kB/s eta 0:54:40\n",
      "    --------------------------------------- 3.4/212.5 MB 63.8 kB/s eta 0:54:40\n",
      "    --------------------------------------- 3.4/212.5 MB 63.8 kB/s eta 0:54:40\n",
      "    --------------------------------------- 3.4/212.5 MB 63.8 kB/s eta 0:54:40\n",
      "    --------------------------------------- 3.4/212.5 MB 63.8 kB/s eta 0:54:40\n",
      "    --------------------------------------- 3.4/212.5 MB 63.8 kB/s eta 0:54:40\n",
      "    --------------------------------------- 3.4/212.5 MB 63.8 kB/s eta 0:54:40\n",
      "    --------------------------------------- 3.4/212.5 MB 63.8 kB/s eta 0:54:40\n",
      "    --------------------------------------- 3.4/212.5 MB 63.8 kB/s eta 0:54:40\n",
      "    --------------------------------------- 3.4/212.5 MB 63.8 kB/s eta 0:54:40\n",
      "    --------------------------------------- 3.4/212.5 MB 63.8 kB/s eta 0:54:40\n",
      "    --------------------------------------- 3.4/212.5 MB 63.8 kB/s eta 0:54:40\n",
      "    --------------------------------------- 3.4/212.5 MB 63.8 kB/s eta 0:54:40\n",
      "    --------------------------------------- 3.4/212.5 MB 63.8 kB/s eta 0:54:40\n",
      "    --------------------------------------- 3.4/212.5 MB 63.8 kB/s eta 0:54:40\n",
      "    --------------------------------------- 3.4/212.5 MB 63.8 kB/s eta 0:54:40\n",
      "    --------------------------------------- 3.4/212.5 MB 63.8 kB/s eta 0:54:40\n",
      "    --------------------------------------- 3.7/212.5 MB 62.2 kB/s eta 0:55:59\n",
      "    --------------------------------------- 3.7/212.5 MB 62.2 kB/s eta 0:55:59\n",
      "    --------------------------------------- 3.7/212.5 MB 62.2 kB/s eta 0:55:59\n",
      "    --------------------------------------- 3.7/212.5 MB 62.2 kB/s eta 0:55:59\n",
      "    --------------------------------------- 3.7/212.5 MB 62.2 kB/s eta 0:55:59\n",
      "    --------------------------------------- 3.7/212.5 MB 62.2 kB/s eta 0:55:59\n",
      "    --------------------------------------- 3.7/212.5 MB 62.2 kB/s eta 0:55:59\n",
      "    --------------------------------------- 3.7/212.5 MB 62.2 kB/s eta 0:55:59\n",
      "    --------------------------------------- 3.7/212.5 MB 62.2 kB/s eta 0:55:59\n",
      "    --------------------------------------- 3.7/212.5 MB 62.2 kB/s eta 0:55:59\n",
      "    --------------------------------------- 3.7/212.5 MB 62.2 kB/s eta 0:55:59\n",
      "    --------------------------------------- 3.7/212.5 MB 62.2 kB/s eta 0:55:59\n",
      "    --------------------------------------- 3.7/212.5 MB 62.2 kB/s eta 0:55:59\n",
      "    --------------------------------------- 3.7/212.5 MB 62.2 kB/s eta 0:55:59\n",
      "    --------------------------------------- 3.7/212.5 MB 62.2 kB/s eta 0:55:59\n",
      "    --------------------------------------- 3.7/212.5 MB 62.2 kB/s eta 0:55:59\n",
      "    --------------------------------------- 3.7/212.5 MB 62.2 kB/s eta 0:55:59\n",
      "    --------------------------------------- 3.7/212.5 MB 62.2 kB/s eta 0:55:59\n",
      "    --------------------------------------- 3.7/212.5 MB 62.2 kB/s eta 0:55:59\n",
      "    --------------------------------------- 3.7/212.5 MB 62.2 kB/s eta 0:55:59\n",
      "    --------------------------------------- 3.7/212.5 MB 62.2 kB/s eta 0:55:59\n",
      "    --------------------------------------- 3.7/212.5 MB 62.2 kB/s eta 0:55:59\n",
      "    --------------------------------------- 3.7/212.5 MB 62.2 kB/s eta 0:55:59\n",
      "    --------------------------------------- 3.7/212.5 MB 62.2 kB/s eta 0:55:59\n",
      "    --------------------------------------- 3.7/212.5 MB 62.2 kB/s eta 0:55:59\n",
      "    --------------------------------------- 3.7/212.5 MB 62.2 kB/s eta 0:55:59\n",
      "    --------------------------------------- 3.7/212.5 MB 62.2 kB/s eta 0:55:59\n",
      "    --------------------------------------- 3.7/212.5 MB 62.2 kB/s eta 0:55:59\n",
      "    --------------------------------------- 3.7/212.5 MB 62.2 kB/s eta 0:55:59\n",
      "    --------------------------------------- 3.7/212.5 MB 62.2 kB/s eta 0:55:59\n",
      "    --------------------------------------- 3.7/212.5 MB 62.2 kB/s eta 0:55:59\n",
      "    --------------------------------------- 3.7/212.5 MB 62.2 kB/s eta 0:55:59\n",
      "    --------------------------------------- 3.7/212.5 MB 62.2 kB/s eta 0:55:59\n",
      "    --------------------------------------- 3.9/212.5 MB 55.6 kB/s eta 1:02:28\n",
      "    --------------------------------------- 3.9/212.5 MB 55.6 kB/s eta 1:02:28\n",
      "    --------------------------------------- 3.9/212.5 MB 55.6 kB/s eta 1:02:28\n",
      "    --------------------------------------- 3.9/212.5 MB 55.6 kB/s eta 1:02:28\n",
      "    --------------------------------------- 3.9/212.5 MB 55.6 kB/s eta 1:02:28\n",
      "    --------------------------------------- 3.9/212.5 MB 55.6 kB/s eta 1:02:28\n",
      "    --------------------------------------- 3.9/212.5 MB 55.6 kB/s eta 1:02:28\n",
      "    --------------------------------------- 3.9/212.5 MB 55.6 kB/s eta 1:02:28\n",
      "    --------------------------------------- 3.9/212.5 MB 55.6 kB/s eta 1:02:28\n",
      "    --------------------------------------- 3.9/212.5 MB 55.6 kB/s eta 1:02:28\n",
      "    --------------------------------------- 3.9/212.5 MB 55.6 kB/s eta 1:02:28\n",
      "    --------------------------------------- 3.9/212.5 MB 55.6 kB/s eta 1:02:28\n",
      "    --------------------------------------- 3.9/212.5 MB 55.6 kB/s eta 1:02:28\n",
      "    --------------------------------------- 3.9/212.5 MB 55.6 kB/s eta 1:02:28\n",
      "    --------------------------------------- 3.9/212.5 MB 55.6 kB/s eta 1:02:28\n",
      "    --------------------------------------- 3.9/212.5 MB 55.6 kB/s eta 1:02:28\n",
      "    --------------------------------------- 3.9/212.5 MB 55.6 kB/s eta 1:02:28\n",
      "    --------------------------------------- 3.9/212.5 MB 55.6 kB/s eta 1:02:28\n",
      "    --------------------------------------- 3.9/212.5 MB 55.6 kB/s eta 1:02:28\n",
      "    --------------------------------------- 3.9/212.5 MB 55.6 kB/s eta 1:02:28\n",
      "    --------------------------------------- 3.9/212.5 MB 55.6 kB/s eta 1:02:28\n",
      "    --------------------------------------- 3.9/212.5 MB 55.6 kB/s eta 1:02:28\n",
      "    --------------------------------------- 4.2/212.5 MB 53.9 kB/s eta 1:04:26\n",
      "    --------------------------------------- 4.2/212.5 MB 53.9 kB/s eta 1:04:26\n",
      "    --------------------------------------- 4.2/212.5 MB 53.9 kB/s eta 1:04:26\n",
      "    --------------------------------------- 4.2/212.5 MB 53.9 kB/s eta 1:04:26\n",
      "    --------------------------------------- 4.2/212.5 MB 53.9 kB/s eta 1:04:26\n",
      "    --------------------------------------- 4.2/212.5 MB 53.9 kB/s eta 1:04:26\n",
      "    --------------------------------------- 4.2/212.5 MB 53.9 kB/s eta 1:04:26\n",
      "    --------------------------------------- 4.2/212.5 MB 53.9 kB/s eta 1:04:26\n",
      "    --------------------------------------- 4.2/212.5 MB 53.9 kB/s eta 1:04:26\n",
      "    --------------------------------------- 4.2/212.5 MB 53.9 kB/s eta 1:04:26\n",
      "    --------------------------------------- 4.2/212.5 MB 53.9 kB/s eta 1:04:26\n",
      "    --------------------------------------- 4.2/212.5 MB 53.9 kB/s eta 1:04:26\n",
      "    --------------------------------------- 4.2/212.5 MB 53.9 kB/s eta 1:04:26\n",
      "    --------------------------------------- 4.2/212.5 MB 53.9 kB/s eta 1:04:26\n",
      "    --------------------------------------- 4.2/212.5 MB 53.9 kB/s eta 1:04:26\n",
      "    --------------------------------------- 4.2/212.5 MB 53.9 kB/s eta 1:04:26\n",
      "    --------------------------------------- 4.2/212.5 MB 53.9 kB/s eta 1:04:26\n",
      "    --------------------------------------- 4.2/212.5 MB 53.9 kB/s eta 1:04:26\n",
      "    --------------------------------------- 4.2/212.5 MB 53.9 kB/s eta 1:04:26\n",
      "    --------------------------------------- 4.2/212.5 MB 53.9 kB/s eta 1:04:26\n",
      "    --------------------------------------- 4.2/212.5 MB 53.9 kB/s eta 1:04:26\n",
      "    --------------------------------------- 4.2/212.5 MB 53.9 kB/s eta 1:04:26\n",
      "    --------------------------------------- 4.2/212.5 MB 53.9 kB/s eta 1:04:26\n",
      "    --------------------------------------- 4.2/212.5 MB 53.9 kB/s eta 1:04:26\n",
      "    --------------------------------------- 4.2/212.5 MB 53.9 kB/s eta 1:04:26\n",
      "    --------------------------------------- 4.2/212.5 MB 53.9 kB/s eta 1:04:26\n",
      "    --------------------------------------- 4.2/212.5 MB 53.9 kB/s eta 1:04:26\n",
      "    --------------------------------------- 4.2/212.5 MB 53.9 kB/s eta 1:04:26\n",
      "    --------------------------------------- 4.2/212.5 MB 53.9 kB/s eta 1:04:26\n",
      "    --------------------------------------- 4.2/212.5 MB 53.9 kB/s eta 1:04:26\n",
      "    --------------------------------------- 4.2/212.5 MB 53.9 kB/s eta 1:04:26\n",
      "    --------------------------------------- 4.2/212.5 MB 53.9 kB/s eta 1:04:26\n",
      "    --------------------------------------- 4.5/212.5 MB 48.9 kB/s eta 1:10:51\n",
      "    --------------------------------------- 4.5/212.5 MB 48.9 kB/s eta 1:10:51\n",
      "    --------------------------------------- 4.5/212.5 MB 48.9 kB/s eta 1:10:51\n",
      "    --------------------------------------- 4.5/212.5 MB 48.9 kB/s eta 1:10:51\n",
      "    --------------------------------------- 4.5/212.5 MB 48.9 kB/s eta 1:10:51\n",
      "    --------------------------------------- 4.5/212.5 MB 48.9 kB/s eta 1:10:51\n",
      "    --------------------------------------- 4.5/212.5 MB 48.9 kB/s eta 1:10:51\n",
      "    --------------------------------------- 4.5/212.5 MB 48.9 kB/s eta 1:10:51\n",
      "    --------------------------------------- 4.5/212.5 MB 48.9 kB/s eta 1:10:51\n",
      "    --------------------------------------- 4.5/212.5 MB 48.9 kB/s eta 1:10:51\n",
      "    --------------------------------------- 4.5/212.5 MB 48.9 kB/s eta 1:10:51\n",
      "    --------------------------------------- 4.5/212.5 MB 48.9 kB/s eta 1:10:51\n",
      "    --------------------------------------- 4.5/212.5 MB 48.9 kB/s eta 1:10:51\n",
      "    --------------------------------------- 4.5/212.5 MB 48.9 kB/s eta 1:10:51\n",
      "    --------------------------------------- 4.5/212.5 MB 48.9 kB/s eta 1:10:51\n",
      "    --------------------------------------- 4.5/212.5 MB 48.9 kB/s eta 1:10:51\n",
      "    --------------------------------------- 4.5/212.5 MB 48.9 kB/s eta 1:10:51\n",
      "    --------------------------------------- 4.5/212.5 MB 48.9 kB/s eta 1:10:51\n",
      "    --------------------------------------- 4.5/212.5 MB 48.9 kB/s eta 1:10:51\n",
      "    --------------------------------------- 4.7/212.5 MB 49.4 kB/s eta 1:10:06\n",
      "    --------------------------------------- 4.7/212.5 MB 49.4 kB/s eta 1:10:06\n",
      "    --------------------------------------- 4.7/212.5 MB 49.4 kB/s eta 1:10:06\n",
      "    --------------------------------------- 4.7/212.5 MB 49.4 kB/s eta 1:10:06\n",
      "    --------------------------------------- 4.7/212.5 MB 49.4 kB/s eta 1:10:06\n",
      "    --------------------------------------- 4.7/212.5 MB 49.4 kB/s eta 1:10:06\n",
      "    --------------------------------------- 4.7/212.5 MB 49.4 kB/s eta 1:10:06\n",
      "    --------------------------------------- 4.7/212.5 MB 49.4 kB/s eta 1:10:06\n",
      "    --------------------------------------- 4.7/212.5 MB 49.4 kB/s eta 1:10:06\n",
      "    --------------------------------------- 4.7/212.5 MB 49.4 kB/s eta 1:10:06\n",
      "    --------------------------------------- 4.7/212.5 MB 49.4 kB/s eta 1:10:06\n",
      "    --------------------------------------- 4.7/212.5 MB 49.4 kB/s eta 1:10:06\n",
      "    --------------------------------------- 4.7/212.5 MB 49.4 kB/s eta 1:10:06\n",
      "    --------------------------------------- 4.7/212.5 MB 49.4 kB/s eta 1:10:06\n",
      "    --------------------------------------- 4.7/212.5 MB 49.4 kB/s eta 1:10:06\n",
      "    --------------------------------------- 4.7/212.5 MB 49.4 kB/s eta 1:10:06\n",
      "    --------------------------------------- 4.7/212.5 MB 49.4 kB/s eta 1:10:06\n",
      "    --------------------------------------- 4.7/212.5 MB 49.4 kB/s eta 1:10:06\n",
      "    --------------------------------------- 4.7/212.5 MB 49.4 kB/s eta 1:10:06\n",
      "    --------------------------------------- 4.7/212.5 MB 49.4 kB/s eta 1:10:06\n",
      "    --------------------------------------- 4.7/212.5 MB 49.4 kB/s eta 1:10:06\n",
      "    --------------------------------------- 4.7/212.5 MB 49.4 kB/s eta 1:10:06\n",
      "    --------------------------------------- 4.7/212.5 MB 49.4 kB/s eta 1:10:06\n",
      "    --------------------------------------- 4.7/212.5 MB 49.4 kB/s eta 1:10:06\n",
      "    --------------------------------------- 4.7/212.5 MB 49.4 kB/s eta 1:10:06\n",
      "    --------------------------------------- 4.7/212.5 MB 49.4 kB/s eta 1:10:06\n",
      "    --------------------------------------- 4.7/212.5 MB 49.4 kB/s eta 1:10:06\n",
      "    --------------------------------------- 5.0/212.5 MB 47.0 kB/s eta 1:13:36\n",
      "    --------------------------------------- 5.0/212.5 MB 47.0 kB/s eta 1:13:36\n",
      "    --------------------------------------- 5.0/212.5 MB 47.0 kB/s eta 1:13:36\n",
      "    --------------------------------------- 5.0/212.5 MB 47.0 kB/s eta 1:13:36\n",
      "    --------------------------------------- 5.0/212.5 MB 47.0 kB/s eta 1:13:36\n",
      "    --------------------------------------- 5.0/212.5 MB 47.0 kB/s eta 1:13:36\n",
      "    --------------------------------------- 5.0/212.5 MB 47.0 kB/s eta 1:13:36\n",
      "    --------------------------------------- 5.0/212.5 MB 47.0 kB/s eta 1:13:36\n",
      "    --------------------------------------- 5.0/212.5 MB 47.0 kB/s eta 1:13:36\n",
      "    --------------------------------------- 5.0/212.5 MB 47.0 kB/s eta 1:13:36\n",
      "    --------------------------------------- 5.0/212.5 MB 47.0 kB/s eta 1:13:36\n",
      "    --------------------------------------- 5.0/212.5 MB 47.0 kB/s eta 1:13:36\n",
      "    --------------------------------------- 5.0/212.5 MB 47.0 kB/s eta 1:13:36\n",
      "    --------------------------------------- 5.0/212.5 MB 47.0 kB/s eta 1:13:36\n",
      "    --------------------------------------- 5.0/212.5 MB 47.0 kB/s eta 1:13:36\n",
      "    --------------------------------------- 5.0/212.5 MB 47.0 kB/s eta 1:13:36\n",
      "    --------------------------------------- 5.0/212.5 MB 47.0 kB/s eta 1:13:36\n",
      "    --------------------------------------- 5.0/212.5 MB 47.0 kB/s eta 1:13:36\n",
      "    --------------------------------------- 5.0/212.5 MB 47.0 kB/s eta 1:13:36\n",
      "    --------------------------------------- 5.0/212.5 MB 47.0 kB/s eta 1:13:36\n",
      "    --------------------------------------- 5.2/212.5 MB 51.9 kB/s eta 1:06:30\n",
      "    --------------------------------------- 5.2/212.5 MB 51.9 kB/s eta 1:06:30\n",
      "    --------------------------------------- 5.2/212.5 MB 51.9 kB/s eta 1:06:30\n",
      "    --------------------------------------- 5.2/212.5 MB 51.9 kB/s eta 1:06:30\n",
      "    --------------------------------------- 5.2/212.5 MB 51.9 kB/s eta 1:06:30\n",
      "    --------------------------------------- 5.2/212.5 MB 51.9 kB/s eta 1:06:30\n",
      "    --------------------------------------- 5.2/212.5 MB 51.9 kB/s eta 1:06:30\n",
      "    --------------------------------------- 5.2/212.5 MB 51.9 kB/s eta 1:06:30\n",
      "    --------------------------------------- 5.2/212.5 MB 51.9 kB/s eta 1:06:30\n",
      "    --------------------------------------- 5.2/212.5 MB 51.9 kB/s eta 1:06:30\n",
      "    --------------------------------------- 5.2/212.5 MB 51.9 kB/s eta 1:06:30\n",
      "    --------------------------------------- 5.2/212.5 MB 51.9 kB/s eta 1:06:30\n",
      "    --------------------------------------- 5.2/212.5 MB 51.9 kB/s eta 1:06:30\n",
      "    --------------------------------------- 5.2/212.5 MB 51.9 kB/s eta 1:06:30\n",
      "    --------------------------------------- 5.2/212.5 MB 51.9 kB/s eta 1:06:30\n",
      "    --------------------------------------- 5.2/212.5 MB 51.9 kB/s eta 1:06:30\n",
      "    --------------------------------------- 5.2/212.5 MB 51.9 kB/s eta 1:06:30\n",
      "    --------------------------------------- 5.2/212.5 MB 51.9 kB/s eta 1:06:30\n",
      "    --------------------------------------- 5.2/212.5 MB 51.9 kB/s eta 1:06:30\n",
      "    --------------------------------------- 5.2/212.5 MB 51.9 kB/s eta 1:06:30\n",
      "    --------------------------------------- 5.2/212.5 MB 51.9 kB/s eta 1:06:30\n",
      "    --------------------------------------- 5.2/212.5 MB 51.9 kB/s eta 1:06:30\n",
      "    --------------------------------------- 5.2/212.5 MB 51.9 kB/s eta 1:06:30\n",
      "    --------------------------------------- 5.2/212.5 MB 51.9 kB/s eta 1:06:30\n",
      "    --------------------------------------- 5.2/212.5 MB 51.9 kB/s eta 1:06:30\n",
      "    --------------------------------------- 5.2/212.5 MB 51.9 kB/s eta 1:06:30\n",
      "   - -------------------------------------- 5.5/212.5 MB 50.3 kB/s eta 1:08:36\n",
      "   - -------------------------------------- 5.5/212.5 MB 50.3 kB/s eta 1:08:36\n",
      "   - -------------------------------------- 5.5/212.5 MB 50.3 kB/s eta 1:08:36\n",
      "   - -------------------------------------- 5.5/212.5 MB 50.3 kB/s eta 1:08:36\n",
      "   - -------------------------------------- 5.5/212.5 MB 50.3 kB/s eta 1:08:36\n",
      "   - -------------------------------------- 5.5/212.5 MB 50.3 kB/s eta 1:08:36\n",
      "   - -------------------------------------- 5.5/212.5 MB 50.3 kB/s eta 1:08:36\n",
      "   - -------------------------------------- 5.5/212.5 MB 50.3 kB/s eta 1:08:36\n",
      "   - -------------------------------------- 5.5/212.5 MB 50.3 kB/s eta 1:08:36\n",
      "   - -------------------------------------- 5.5/212.5 MB 50.3 kB/s eta 1:08:36\n",
      "   - -------------------------------------- 5.5/212.5 MB 50.3 kB/s eta 1:08:36\n",
      "   - -------------------------------------- 5.5/212.5 MB 50.3 kB/s eta 1:08:36\n",
      "   - -------------------------------------- 5.5/212.5 MB 50.3 kB/s eta 1:08:36\n",
      "   - -------------------------------------- 5.5/212.5 MB 50.3 kB/s eta 1:08:36\n",
      "   - -------------------------------------- 5.5/212.5 MB 50.3 kB/s eta 1:08:36\n",
      "   - -------------------------------------- 5.5/212.5 MB 50.3 kB/s eta 1:08:36\n",
      "   - -------------------------------------- 5.5/212.5 MB 50.3 kB/s eta 1:08:36\n",
      "   - -------------------------------------- 5.5/212.5 MB 50.3 kB/s eta 1:08:36\n",
      "   - -------------------------------------- 5.5/212.5 MB 50.3 kB/s eta 1:08:36\n",
      "   - -------------------------------------- 5.5/212.5 MB 50.3 kB/s eta 1:08:36\n",
      "   - -------------------------------------- 5.5/212.5 MB 50.3 kB/s eta 1:08:36\n",
      "   - -------------------------------------- 5.5/212.5 MB 50.3 kB/s eta 1:08:36\n",
      "   - -------------------------------------- 5.5/212.5 MB 50.3 kB/s eta 1:08:36\n",
      "   - -------------------------------------- 5.5/212.5 MB 50.3 kB/s eta 1:08:36\n",
      "   - -------------------------------------- 5.5/212.5 MB 50.3 kB/s eta 1:08:36\n",
      "   - -------------------------------------- 5.5/212.5 MB 50.3 kB/s eta 1:08:36\n",
      "   - -------------------------------------- 5.8/212.5 MB 52.5 kB/s eta 1:05:36\n",
      "   - -------------------------------------- 5.8/212.5 MB 52.5 kB/s eta 1:05:36\n",
      "   - -------------------------------------- 5.8/212.5 MB 52.5 kB/s eta 1:05:36\n",
      "   - -------------------------------------- 5.8/212.5 MB 52.5 kB/s eta 1:05:36\n",
      "   - -------------------------------------- 5.8/212.5 MB 52.5 kB/s eta 1:05:36\n",
      "   - -------------------------------------- 6.0/212.5 MB 60.4 kB/s eta 0:56:59\n",
      "   - -------------------------------------- 6.0/212.5 MB 60.4 kB/s eta 0:56:59\n",
      "   - -------------------------------------- 6.0/212.5 MB 60.4 kB/s eta 0:56:59\n",
      "   - -------------------------------------- 6.3/212.5 MB 68.8 kB/s eta 0:49:56\n",
      "   - -------------------------------------- 6.3/212.5 MB 68.8 kB/s eta 0:49:56\n",
      "   - -------------------------------------- 6.6/212.5 MB 77.3 kB/s eta 0:44:25\n",
      "   - -------------------------------------- 6.6/212.5 MB 77.3 kB/s eta 0:44:25\n",
      "   - -------------------------------------- 6.8/212.5 MB 85.6 kB/s eta 0:40:02\n",
      "   - -------------------------------------- 6.8/212.5 MB 85.6 kB/s eta 0:40:02\n",
      "   - -------------------------------------- 7.1/212.5 MB 93.9 kB/s eta 0:36:28\n",
      "   - -------------------------------------- 7.3/212.5 MB 102.1 kB/s eta 0:33:29\n",
      "   - -------------------------------------- 7.3/212.5 MB 102.1 kB/s eta 0:33:29\n",
      "   - -------------------------------------- 7.6/212.5 MB 110.2 kB/s eta 0:31:00\n",
      "   - -------------------------------------- 7.9/212.5 MB 118.2 kB/s eta 0:28:51\n",
      "   - -------------------------------------- 8.1/212.5 MB 126.2 kB/s eta 0:27:00\n",
      "   - -------------------------------------- 8.4/212.5 MB 134.1 kB/s eta 0:25:23\n",
      "   - -------------------------------------- 8.4/212.5 MB 134.1 kB/s eta 0:25:23\n",
      "   - -------------------------------------- 8.7/212.5 MB 141.8 kB/s eta 0:23:58\n",
      "   - -------------------------------------- 8.9/212.5 MB 149.5 kB/s eta 0:22:42\n",
      "   - -------------------------------------- 9.2/212.5 MB 171.4 kB/s eta 0:19:47\n",
      "   - -------------------------------------- 9.4/212.5 MB 180.0 kB/s eta 0:18:49\n",
      "   - ------------------------------------- 10.0/212.5 MB 197.2 kB/s eta 0:17:08\n",
      "   - ------------------------------------- 10.2/212.5 MB 205.7 kB/s eta 0:16:24\n",
      "   - ------------------------------------- 10.5/212.5 MB 214.3 kB/s eta 0:15:43\n",
      "   -- ------------------------------------ 11.0/212.5 MB 231.4 kB/s eta 0:14:31\n",
      "   -- ------------------------------------ 11.5/212.5 MB 248.6 kB/s eta 0:13:29\n",
      "   -- ------------------------------------ 12.1/212.5 MB 265.4 kB/s eta 0:12:36\n",
      "   -- ------------------------------------ 12.6/212.5 MB 282.3 kB/s eta 0:11:49\n",
      "   -- ------------------------------------ 13.1/212.5 MB 299.3 kB/s eta 0:11:07\n",
      "   -- ------------------------------------ 13.9/212.5 MB 324.4 kB/s eta 0:10:13\n",
      "   -- ------------------------------------ 14.7/212.5 MB 349.5 kB/s eta 0:09:26\n",
      "   -- ------------------------------------ 15.5/212.5 MB 374.5 kB/s eta 0:08:47\n",
      "   -- ------------------------------------ 16.3/212.5 MB 399.2 kB/s eta 0:08:12\n",
      "   --- ----------------------------------- 17.3/212.5 MB 432.0 kB/s eta 0:07:32\n",
      "   --- ----------------------------------- 18.4/212.5 MB 464.8 kB/s eta 0:06:58\n",
      "   --- ----------------------------------- 19.4/212.5 MB 496.9 kB/s eta 0:06:29\n",
      "   --- ----------------------------------- 20.4/212.5 MB 529.0 kB/s eta 0:06:04\n",
      "   --- ----------------------------------- 21.5/212.5 MB 560.7 kB/s eta 0:05:41\n",
      "   ---- ---------------------------------- 22.3/212.5 MB 709.8 kB/s eta 0:04:28\n",
      "   ---- ---------------------------------- 23.6/212.5 MB 756.8 kB/s eta 0:04:10\n",
      "   ---- ---------------------------------- 25.2/212.5 MB 813.5 kB/s eta 0:03:51\n",
      "   ---- ---------------------------------- 26.0/212.5 MB 838.9 kB/s eta 0:03:43\n",
      "   ---- ---------------------------------- 26.7/212.5 MB 862.2 kB/s eta 0:03:36\n",
      "   ----- --------------------------------- 27.3/212.5 MB 878.7 kB/s eta 0:03:31\n",
      "   ----- --------------------------------- 28.6/212.5 MB 918.5 kB/s eta 0:03:21\n",
      "   ----- --------------------------------- 29.6/212.5 MB 951.8 kB/s eta 0:03:13\n",
      "   ----- ---------------------------------- 31.2/212.5 MB 1.0 MB/s eta 0:03:01\n",
      "   ------ --------------------------------- 32.8/212.5 MB 1.1 MB/s eta 0:02:51\n",
      "   ------ --------------------------------- 34.6/212.5 MB 1.1 MB/s eta 0:02:40\n",
      "   ------ --------------------------------- 36.7/212.5 MB 1.2 MB/s eta 0:02:28\n",
      "   ------- -------------------------------- 38.5/212.5 MB 1.2 MB/s eta 0:02:20\n",
      "   ------- -------------------------------- 40.4/212.5 MB 1.3 MB/s eta 0:02:12\n",
      "   ------- -------------------------------- 42.5/212.5 MB 1.4 MB/s eta 0:02:05\n",
      "   -------- ------------------------------- 44.8/212.5 MB 1.4 MB/s eta 0:01:56\n",
      "   -------- ------------------------------- 46.1/212.5 MB 1.5 MB/s eta 0:01:53\n",
      "   --------- ------------------------------ 48.5/212.5 MB 1.6 MB/s eta 0:01:46\n",
      "   --------- ------------------------------ 51.4/212.5 MB 1.6 MB/s eta 0:01:38\n",
      "   ---------- ----------------------------- 55.1/212.5 MB 1.8 MB/s eta 0:01:30\n",
      "   ----------- ---------------------------- 58.7/212.5 MB 1.9 MB/s eta 0:01:22\n",
      "   ----------- ---------------------------- 62.4/212.5 MB 2.0 MB/s eta 0:01:16\n",
      "   ------------ --------------------------- 66.8/212.5 MB 2.1 MB/s eta 0:01:09\n",
      "   ------------- -------------------------- 70.5/212.5 MB 2.2 MB/s eta 0:01:04\n",
      "   -------------- ------------------------- 75.2/212.5 MB 2.4 MB/s eta 0:00:58\n",
      "   --------------- ------------------------ 80.5/212.5 MB 2.5 MB/s eta 0:00:52\n",
      "   --------------- ------------------------ 83.1/212.5 MB 2.6 MB/s eta 0:00:50\n",
      "   ---------------- ----------------------- 86.5/212.5 MB 3.2 MB/s eta 0:00:40\n",
      "   ----------------- ---------------------- 91.0/212.5 MB 3.3 MB/s eta 0:00:37\n",
      "   ----------------- ---------------------- 95.4/212.5 MB 3.4 MB/s eta 0:00:34\n",
      "   ------------------ --------------------- 100.4/212.5 MB 3.6 MB/s eta 0:00:32\n",
      "   ------------------- -------------------- 104.3/212.5 MB 3.7 MB/s eta 0:00:30\n",
      "   -------------------- ------------------- 108.3/212.5 MB 3.8 MB/s eta 0:00:28\n",
      "   --------------------- ------------------ 112.5/212.5 MB 4.0 MB/s eta 0:00:26\n",
      "   --------------------- ------------------ 115.6/212.5 MB 4.1 MB/s eta 0:00:24\n",
      "   ---------------------- ----------------- 120.8/212.5 MB 4.2 MB/s eta 0:00:22\n",
      "   ----------------------- ---------------- 126.9/212.5 MB 4.4 MB/s eta 0:00:20\n",
      "   ------------------------ --------------- 129.5/212.5 MB 4.5 MB/s eta 0:00:19\n",
      "   ------------------------- -------------- 134.5/212.5 MB 4.6 MB/s eta 0:00:17\n",
      "   -------------------------- ------------- 138.4/212.5 MB 4.7 MB/s eta 0:00:16\n",
      "   -------------------------- ------------- 142.3/212.5 MB 4.8 MB/s eta 0:00:15\n",
      "   --------------------------- ------------ 146.3/212.5 MB 4.9 MB/s eta 0:00:14\n",
      "   ---------------------------- ----------- 149.9/212.5 MB 5.0 MB/s eta 0:00:13\n",
      "   ---------------------------- ----------- 153.6/212.5 MB 5.1 MB/s eta 0:00:12\n",
      "   ----------------------------- ---------- 157.5/212.5 MB 5.2 MB/s eta 0:00:11\n",
      "   ------------------------------ --------- 162.0/212.5 MB 5.3 MB/s eta 0:00:10\n",
      "   ------------------------------- -------- 165.7/212.5 MB 5.4 MB/s eta 0:00:09\n",
      "   ------------------------------- -------- 169.9/212.5 MB 5.5 MB/s eta 0:00:08\n",
      "   -------------------------------- ------- 173.5/212.5 MB 6.8 MB/s eta 0:00:06\n",
      "   --------------------------------- ------ 177.2/212.5 MB 6.9 MB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 180.9/212.5 MB 6.9 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 184.0/212.5 MB 7.0 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 188.0/212.5 MB 7.1 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 191.9/212.5 MB 7.2 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 195.6/212.5 MB 7.3 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 200.0/212.5 MB 7.4 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 204.5/212.5 MB 7.5 MB/s eta 0:00:02\n",
      "   ---------------------------------------  208.4/212.5 MB 7.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  211.3/212.5 MB 7.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  212.3/212.5 MB 7.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  212.3/212.5 MB 7.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  212.3/212.5 MB 7.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  212.3/212.5 MB 7.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  212.3/212.5 MB 7.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  212.3/212.5 MB 7.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  212.3/212.5 MB 7.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  212.3/212.5 MB 7.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  212.3/212.5 MB 7.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 212.5/212.5 MB 7.2 MB/s eta 0:00:00\n",
      "Downloading torchvision-0.22.0-cp312-cp312-win_amd64.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.7/1.7 MB 15.6 MB/s eta 0:00:00\n",
      "Downloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
      "Downloading sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
      "   ---------------------------------------- 0.0/6.2 MB ? eta -:--:--\n",
      "   ---------------------------- ----------- 4.5/6.2 MB 22.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.2/6.2 MB 18.1 MB/s eta 0:00:00\n",
      "Installing collected packages: sympy, opencv-python, torch, ultralytics-thop, torchvision, ultralytics\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.13.2\n",
      "    Uninstalling sympy-1.13.2:\n",
      "      Successfully uninstalled sympy-1.13.2\n",
      "Successfully installed opencv-python-4.11.0.86 sympy-1.13.3 torch-2.7.0 torchvision-0.22.0 ultralytics-8.3.117 ultralytics-thop-2.0.14\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c1e19f5-6fa9-4557-ab8a-ac38a8ec0a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 115.5ms\n",
      "Speed: 3.9ms preprocess, 115.5ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 136.3ms\n",
      "Speed: 3.6ms preprocess, 136.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 155.7ms\n",
      "Speed: 4.5ms preprocess, 155.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 126.4ms\n",
      "Speed: 2.5ms preprocess, 126.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 130.4ms\n",
      "Speed: 2.4ms preprocess, 130.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 166.7ms\n",
      "Speed: 3.0ms preprocess, 166.7ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 140.6ms\n",
      "Speed: 3.5ms preprocess, 140.6ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 150.0ms\n",
      "Speed: 3.1ms preprocess, 150.0ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 137.5ms\n",
      "Speed: 2.8ms preprocess, 137.5ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 127.0ms\n",
      "Speed: 3.1ms preprocess, 127.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 159.4ms\n",
      "Speed: 3.6ms preprocess, 159.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 136.0ms\n",
      "Speed: 3.3ms preprocess, 136.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 116.7ms\n",
      "Speed: 3.3ms preprocess, 116.7ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 122.6ms\n",
      "Speed: 3.8ms preprocess, 122.6ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 143.1ms\n",
      "Speed: 3.5ms preprocess, 143.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 130.1ms\n",
      "Speed: 3.3ms preprocess, 130.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 130.1ms\n",
      "Speed: 4.1ms preprocess, 130.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 127.0ms\n",
      "Speed: 3.8ms preprocess, 127.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 120.2ms\n",
      "Speed: 2.7ms preprocess, 120.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 129.6ms\n",
      "Speed: 3.2ms preprocess, 129.6ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 118.5ms\n",
      "Speed: 2.7ms preprocess, 118.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 131.3ms\n",
      "Speed: 3.4ms preprocess, 131.3ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 127.7ms\n",
      "Speed: 2.9ms preprocess, 127.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 131.2ms\n",
      "Speed: 2.8ms preprocess, 131.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 119.7ms\n",
      "Speed: 4.0ms preprocess, 119.7ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 115.3ms\n",
      "Speed: 3.7ms preprocess, 115.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 113.6ms\n",
      "Speed: 2.7ms preprocess, 113.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 111.7ms\n",
      "Speed: 3.8ms preprocess, 111.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 112.6ms\n",
      "Speed: 2.0ms preprocess, 112.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 131.3ms\n",
      "Speed: 3.4ms preprocess, 131.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 145.0ms\n",
      "Speed: 3.4ms preprocess, 145.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 140.6ms\n",
      "Speed: 3.7ms preprocess, 140.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 129.1ms\n",
      "Speed: 2.6ms preprocess, 129.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 123.8ms\n",
      "Speed: 2.8ms preprocess, 123.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 130.8ms\n",
      "Speed: 2.7ms preprocess, 130.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 135.8ms\n",
      "Speed: 2.8ms preprocess, 135.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 181.1ms\n",
      "Speed: 20.5ms preprocess, 181.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 141.9ms\n",
      "Speed: 5.6ms preprocess, 141.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 113.1ms\n",
      "Speed: 2.4ms preprocess, 113.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 104.4ms\n",
      "Speed: 3.6ms preprocess, 104.4ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 100.4ms\n",
      "Speed: 4.0ms preprocess, 100.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 99.5ms\n",
      "Speed: 2.9ms preprocess, 99.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 105.6ms\n",
      "Speed: 3.0ms preprocess, 105.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 111.7ms\n",
      "Speed: 4.2ms preprocess, 111.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 97.5ms\n",
      "Speed: 4.0ms preprocess, 97.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 96.0ms\n",
      "Speed: 4.0ms preprocess, 96.0ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 91.9ms\n",
      "Speed: 3.7ms preprocess, 91.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 101.8ms\n",
      "Speed: 3.7ms preprocess, 101.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 99.6ms\n",
      "Speed: 2.4ms preprocess, 99.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 112.4ms\n",
      "Speed: 4.7ms preprocess, 112.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 104.1ms\n",
      "Speed: 3.9ms preprocess, 104.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 110.1ms\n",
      "Speed: 3.0ms preprocess, 110.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 115.9ms\n",
      "Speed: 2.6ms preprocess, 115.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 159.8ms\n",
      "Speed: 3.5ms preprocess, 159.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 124.8ms\n",
      "Speed: 3.3ms preprocess, 124.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 111.4ms\n",
      "Speed: 2.5ms preprocess, 111.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 97.0ms\n",
      "Speed: 4.2ms preprocess, 97.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 98.2ms\n",
      "Speed: 3.0ms preprocess, 98.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 89.8ms\n",
      "Speed: 3.4ms preprocess, 89.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 99.0ms\n",
      "Speed: 1.8ms preprocess, 99.0ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 96.5ms\n",
      "Speed: 3.3ms preprocess, 96.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 93.5ms\n",
      "Speed: 2.4ms preprocess, 93.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 102.3ms\n",
      "Speed: 2.5ms preprocess, 102.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 99.8ms\n",
      "Speed: 2.4ms preprocess, 99.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 93.5ms\n",
      "Speed: 4.1ms preprocess, 93.5ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 104.5ms\n",
      "Speed: 2.5ms preprocess, 104.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 108.4ms\n",
      "Speed: 3.6ms preprocess, 108.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 110.3ms\n",
      "Speed: 2.6ms preprocess, 110.3ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 104.0ms\n",
      "Speed: 2.6ms preprocess, 104.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 114.1ms\n",
      "Speed: 3.6ms preprocess, 114.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 110.0ms\n",
      "Speed: 2.6ms preprocess, 110.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 118.7ms\n",
      "Speed: 3.4ms preprocess, 118.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 134.2ms\n",
      "Speed: 3.2ms preprocess, 134.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 138.7ms\n",
      "Speed: 3.3ms preprocess, 138.7ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 142.3ms\n",
      "Speed: 3.2ms preprocess, 142.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 114.6ms\n",
      "Speed: 2.7ms preprocess, 114.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 123.8ms\n",
      "Speed: 3.3ms preprocess, 123.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 108.9ms\n",
      "Speed: 3.0ms preprocess, 108.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 111.8ms\n",
      "Speed: 2.5ms preprocess, 111.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 108.9ms\n",
      "Speed: 2.7ms preprocess, 108.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 121.9ms\n",
      "Speed: 3.2ms preprocess, 121.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 125.3ms\n",
      "Speed: 3.7ms preprocess, 125.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 179.3ms\n",
      "Speed: 13.1ms preprocess, 179.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 136.4ms\n",
      "Speed: 7.6ms preprocess, 136.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 146.1ms\n",
      "Speed: 5.9ms preprocess, 146.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 124.2ms\n",
      "Speed: 2.7ms preprocess, 124.2ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 114.7ms\n",
      "Speed: 4.9ms preprocess, 114.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 142.9ms\n",
      "Speed: 4.3ms preprocess, 142.9ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 124.4ms\n",
      "Speed: 4.1ms preprocess, 124.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 114.1ms\n",
      "Speed: 3.0ms preprocess, 114.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 106.9ms\n",
      "Speed: 3.1ms preprocess, 106.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 122.8ms\n",
      "Speed: 4.5ms preprocess, 122.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 106.4ms\n",
      "Speed: 2.8ms preprocess, 106.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 135.8ms\n",
      "Speed: 3.0ms preprocess, 135.8ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 185.0ms\n",
      "Speed: 3.1ms preprocess, 185.0ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 173.0ms\n",
      "Speed: 3.9ms preprocess, 173.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 150.2ms\n",
      "Speed: 6.0ms preprocess, 150.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 142.9ms\n",
      "Speed: 3.1ms preprocess, 142.9ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 113.2ms\n",
      "Speed: 2.5ms preprocess, 113.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 112.2ms\n",
      "Speed: 2.7ms preprocess, 112.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 120.4ms\n",
      "Speed: 2.4ms preprocess, 120.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 102.2ms\n",
      "Speed: 3.9ms preprocess, 102.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 100.9ms\n",
      "Speed: 3.7ms preprocess, 100.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 121.9ms\n",
      "Speed: 4.8ms preprocess, 121.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 114.6ms\n",
      "Speed: 3.0ms preprocess, 114.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 131.7ms\n",
      "Speed: 2.4ms preprocess, 131.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 142.0ms\n",
      "Speed: 2.6ms preprocess, 142.0ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 145.0ms\n",
      "Speed: 3.8ms preprocess, 145.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 166.0ms\n",
      "Speed: 5.9ms preprocess, 166.0ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 147.3ms\n",
      "Speed: 3.8ms preprocess, 147.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 134.2ms\n",
      "Speed: 2.7ms preprocess, 134.2ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('yolov8n-pose.pt')\n",
    "\n",
    "cap = cv2.VideoCapture(0)  #open webcam\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Run YOLO pose prediction WITHOUT showing\n",
    "    results = model.predict(frame, conf=0.5, stream=True)\n",
    "\n",
    "    for r in results:\n",
    "        # Get the annotated frame from results\n",
    "        annotated_frame = r.plot()\n",
    "\n",
    "        # Show using OpenCV\n",
    "        cv2.imshow('YOLOv8 Pose Detection', annotated_frame)\n",
    "\n",
    "    # Exit when pressing 'f'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('f'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe4a91f8-99a5-4ad0-8e99-b028901d2d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Sequential keypoints saved to: C:/Users/Kassimi/OneDrive/Bureau/cv_data/squat/squat_pose_data.csv\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Load YOLOv8-pose model\n",
    "model = YOLO('yolov8n-pose.pt')\n",
    "\n",
    "\n",
    "data_root = r'C:/Users/Kassimi/OneDrive/Bureau/cv_data/squat/'\n",
    "folders = ['correct_form', 'wrong_form']\n",
    "\n",
    "# Output CSV data\n",
    "output_data = []\n",
    "\n",
    "for label in folders:\n",
    "    folder_path = os.path.join(data_root, label)\n",
    "\n",
    "    for video_file in os.listdir(folder_path):\n",
    "        if not video_file.endswith(('.mp4', '.avi', '.mov')):\n",
    "            continue\n",
    "\n",
    "        video_path = os.path.join(folder_path, video_file)\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        frame_index = 0\n",
    "\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # Pose estimation\n",
    "            results = model.predict(frame, save=False, verbose=False)\n",
    "            keypoints = results[0].keypoints.xy.cpu().numpy()  # shape: (n_person, 17, 2)\n",
    "\n",
    "            if len(keypoints) == 0:\n",
    "                frame_index += 1\n",
    "                continue  # No person detected in frame\n",
    "\n",
    "            # Take only the first person detected\n",
    "            person_keypoints = keypoints[0].flatten()  # shape: (34,)\n",
    "\n",
    "            # Store with metadata\n",
    "            row = [video_file, frame_index] + list(person_keypoints) + [label]\n",
    "            output_data.append(row)\n",
    "\n",
    "            frame_index += 1\n",
    "\n",
    "        cap.release()\n",
    "\n",
    "# Define column names\n",
    "columns = ['video_id', 'frame'] + [f'kp_{i}_{coord}' for i in range(17) for coord in ['x', 'y']] + ['label']\n",
    "df = pd.DataFrame(output_data, columns=columns)\n",
    "\n",
    "# Save to CSV\n",
    "output_csv_path = os.path.join(data_root, 'squat_pose_data.csv')\n",
    "df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f\" Sequential keypoints saved to: {output_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45733487-20c5-4886-8d58-8a4b283ca408",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'correct_1.mp4'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19820\\1593451012.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'correct'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wrong'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Convert labels to 1 (correct) or 0 (wrong)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m# Normalize keypoints using StandardScaler (so all values are on a similar scale)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mscaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mX_scaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;31m# Convert to tensors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mX_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_scaled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    311\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 313\u001b[1;33m         \u001b[0mdata_to_wrap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    314\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m             \u001b[1;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m             return_tuple = (\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m   1094\u001b[0m                 \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1095\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1096\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1097\u001b[0m             \u001b[1;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1101\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    874\u001b[0m             \u001b[0mFitted\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    875\u001b[0m         \"\"\"\n\u001b[0;32m    876\u001b[0m         \u001b[1;31m# Reset internal state before fitting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    877\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 878\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1469\u001b[0m                 skip_parameter_validation=(\n\u001b[0;32m   1470\u001b[0m                     \u001b[0mprefer_skip_nested_validation\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mglobal_skip_validation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1471\u001b[0m                 \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1472\u001b[0m             \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1473\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    910\u001b[0m         \u001b[0mself\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    911\u001b[0m             \u001b[0mFitted\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    912\u001b[0m         \"\"\"\n\u001b[0;32m    913\u001b[0m         \u001b[0mfirst_call\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"n_samples_seen_\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 914\u001b[1;33m         X = self._validate_data(\n\u001b[0m\u001b[0;32m    915\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m             \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    629\u001b[0m                 \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    630\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    631\u001b[0m                 \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    632\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 633\u001b[1;33m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"X\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    634\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    635\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    636\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1009\u001b[0m                         \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1010\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1011\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1012\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1013\u001b[1;33m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1014\u001b[0m                 raise ValueError(\n\u001b[0;32m   1015\u001b[0m                     \u001b[1;34m\"Complex data not supported\\n{}\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m                 \u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[0;32m    747\u001b[0m         \u001b[1;31m# Use NumPy API to support order\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    748\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    749\u001b[0m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    750\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 751\u001b[1;33m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    752\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m         \u001b[1;31m# At this point array is a NumPy ndarray. We convert it to an array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    754\u001b[0m         \u001b[1;31m# container that is consistent with the input's namespace.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, dtype, copy)\u001b[0m\n\u001b[0;32m   2149\u001b[0m     def __array__(\n\u001b[0;32m   2150\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool_t\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2151\u001b[0m     \u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2152\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2153\u001b[1;33m         \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2154\u001b[0m         if (\n\u001b[0;32m   2155\u001b[0m             \u001b[0mastype_is_view\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2156\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0musing_copy_on_write\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'correct_1.mp4'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Load the CSV data\n",
    "df = pd.read_csv(r\"C:\\Users\\Kassimi\\OneDrive\\Bureau\\cv_data\\squat\\squat_pose_data.csv\")\n",
    "\n",
    "# Features (keypoints) and labels\n",
    "X = df.drop(columns=['label'])  # All columns except label are keypoints\n",
    "y = df['label'].map({'correct': 1, 'wrong': 0})  # Convert labels to 1 (correct) or 0 (wrong)\n",
    "\n",
    "# Normalize keypoints using StandardScaler (so all values are on a similar scale)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Convert to tensors\n",
    "X_tensor = torch.tensor(X_scaled, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y.values, dtype=torch.long)\n",
    "\n",
    "# Train-test split (80% training, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_tensor, y_tensor, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a PyTorch dataset for easier batching\n",
    "class SquatDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]\n",
    "\n",
    "# Create DataLoader objects for batching\n",
    "train_dataset = SquatDataset(X_train, y_train)\n",
    "val_dataset = SquatDataset(X_val, y_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b56e5b26-95fd-466a-9dee-22148a57b078",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SquatNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SquatNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(34, 64)  # Input layer to hidden layer\n",
    "        self.fc2 = nn.Linear(64, 32)  # Hidden layer\n",
    "        self.fc3 = nn.Linear(32, 2)   # Output layer (correct or wrong)\n",
    "        self.relu = nn.ReLU()         # Activation function\n",
    "        self.softmax = nn.Softmax(dim=1)  # Softmax for output probabilities\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))  # First hidden layer\n",
    "        x = self.relu(self.fc2(x))  # Second hidden layer\n",
    "        x = self.fc3(x)             # Output layer\n",
    "        return self.softmax(x)      # Softmax activation for probabilities\n",
    "\n",
    "# Initialize the model\n",
    "model = SquatNet()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d03bdd0-dcb1-42cd-b273-341af8e60672",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m correct_preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     12\u001b[0m total_preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m     15\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()   \u001b[38;5;66;03m# Clear the gradients\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(inputs) \u001b[38;5;66;03m# Get predictions from the model\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()  # Used for multi-class classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "    correct_preds = 0\n",
    "    total_preds = 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()   # Clear the gradients\n",
    "        outputs = model(inputs) # Get predictions from the model\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()         # Backpropagation\n",
    "        optimizer.step()        # Update model weights\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total_preds += labels.size(0)\n",
    "        correct_preds += (predicted == labels).sum().item()\n",
    "\n",
    "    # Calculate training accuracy and loss\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_accuracy = correct_preds / total_preds\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    val_loss = 0.0\n",
    "    correct_preds = 0\n",
    "    total_preds = 0\n",
    "    with torch.no_grad():  # No gradient calculation during evaluation\n",
    "        for inputs, labels in val_loader:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # Calculate accuracy\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_preds += labels.size(0)\n",
    "            correct_preds += (predicted == labels).sum().item()\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    val_accuracy = correct_preds / total_preds\n",
    "\n",
    "    # Print training and validation results\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], \"\n",
    "          f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy*100:.2f}%, \"\n",
    "          f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "059f279b-e87a-4f26-8c3b-edd2760a2893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved!\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "torch.save(model.state_dict(), r'C:\\Users\\Kassimi\\OneDrive\\Bureau\\cv_data\\squatsquat_model.pth')\n",
    "print(\"Model saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abe4a10b-12eb-442f-b5cb-89eec5775f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytube in c:\\users\\kassimi\\anaconda3\\lib\\site-packages (15.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pytube\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34cc6eb-8210-40d0-b201-a4025faed657",
   "metadata": {},
   "source": [
    "now to making a prediction on a new video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649b3db7-13d0-4af7-880c-c389166ae115",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142259f2-a885-4c59-8b45-80a8c394c5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "model = SquatNet()\n",
    "model.load_state_dict(torch.load(r'C:\\Users\\Kassimi\\OneDrive\\Bureau\\cv_data\\squatsquat_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "# Load the scaler you used before\n",
    "scaler = StandardScaler()\n",
    "df = pd.read_csv(r\"C:\\Users\\Kassimi\\OneDrive\\Bureau\\cv_data\\squat\\squat_pose_data.csv\")\n",
    "X = df.drop(columns=['label'])\n",
    "scaler.fit(X)  # fit on original data to re-use for new data\n",
    "\n",
    "# Load YOLO pose model again\n",
    "yolo_model = YOLO('yolov8n-pose.pt')\n",
    "\n",
    "# New video path\n",
    "new_video_path = r\"C:\\Users\\Kassimi\\OneDrive\\Bureau\\cv_data\\squat\\correct_form\\correct_11.mp4\"\n",
    "cap = cv2.VideoCapture(new_video_path)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Pose estimation\n",
    "    results = yolo_model.predict(frame, save=False, verbose=False)\n",
    "    keypoints = results[0].keypoints.xy.cpu().numpy()\n",
    "\n",
    "    if len(keypoints) == 0:\n",
    "        continue  # No person detected\n",
    "\n",
    "    # Only first person\n",
    "    person_keypoints = keypoints[0].flatten()\n",
    "\n",
    "    if len(person_keypoints) != 34:  # 17 keypoints * 2 (x,y)\n",
    "        continue  # Safety check\n",
    "\n",
    "    # Scale keypoints\n",
    "    person_keypoints_scaled = scaler.transform([person_keypoints])\n",
    "\n",
    "    # Convert to tensor\n",
    "    input_tensor = torch.tensor(person_keypoints_scaled, dtype=torch.float32)\n",
    "\n",
    "    # Predict\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "        _, predicted_class = torch.max(output, 1)\n",
    "\n",
    "    # Map prediction\n",
    "    label = 'Correct' if predicted_class.item() == 1 else 'Wrong'\n",
    "\n",
    "    # Display result on frame\n",
    "    cv2.putText(frame, label, (30, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 255, 0) if label == 'Correct' else (0, 0, 255), 3)\n",
    "\n",
    "    # Show frame\n",
    "    cv2.imshow('Squat Form Prediction', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b28af42-ed8e-4a85-a229-cc7ba1c7e500",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\Kassimi\\\\OneDrive\\\\Bureau\\\\cv_data\\\\squat_model.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 25\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Load the trained model\u001b[39;00m\n\u001b[0;32m     24\u001b[0m model \u001b[38;5;241m=\u001b[39m SquatNet()\n\u001b[1;32m---> 25\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mKassimi\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mOneDrive\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mBureau\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mcv_data\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124msquat_model.pth\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     26\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m     29\u001b[0m scaler \u001b[38;5;241m=\u001b[39m StandardScaler()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ultralytics\\utils\\patches.py:115\u001b[0m, in \u001b[0;36mtorch_load\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TORCH_1_13 \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights_only\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[0;32m    113\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights_only\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 115\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _torch_load(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\serialization.py:1479\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m   1477\u001b[0m     pickle_load_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1479\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_file_like(f, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m   1480\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m   1481\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m   1482\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m   1483\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m   1484\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\serialization.py:759\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    757\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer: FileLike, mode: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _opener[IO[\u001b[38;5;28mbytes\u001b[39m]]:\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 759\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[0;32m    760\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    761\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\serialization.py:740\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    739\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: Union[\u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike[\u001b[38;5;28mstr\u001b[39m]], mode: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 740\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mopen\u001b[39m(name, mode))\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\Kassimi\\\\OneDrive\\\\Bureau\\\\cv_data\\\\squat_model.pth'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Define SquatNet again\n",
    "class SquatNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SquatNet, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(34, 64)\n",
    "        self.fc2 = torch.nn.Linear(64, 32)\n",
    "        self.fc3 = torch.nn.Linear(32, 2)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.softmax = torch.nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return self.softmax(x)\n",
    "\n",
    "# Load the trained model\n",
    "model = SquatNet()\n",
    "model.load_state_dict(torch.load(r'C:\\Users\\Kassimi\\OneDrive\\Bureau\\cv_data\\squat_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df = pd.read_csv(r\"C:\\Users\\Kassimi\\OneDrive\\Bureau\\cv_data\\squat\\squat_pose_data.csv\")\n",
    "X = df.drop(columns=['label'])\n",
    "scaler.fit(X)\n",
    "\n",
    "# Load YOLOv8 pose model\n",
    "yolo_model = YOLO('yolov8n-pose.pt')\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\" Cannot open webcam\")\n",
    "    exit()\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\" Can't receive frame. Exiting...\")\n",
    "        break\n",
    "\n",
    "    # Pose estimation\n",
    "    results = yolo_model.predict(frame, save=False, verbose=False)\n",
    "    keypoints = results[0].keypoints.xy.cpu().numpy()\n",
    "\n",
    "    if len(keypoints) > 0:\n",
    "        # Only first detected person\n",
    "        person_keypoints = keypoints[0].flatten()\n",
    "\n",
    "        if len(person_keypoints) == 34:  # 17 keypoints * 2 (x, y)\n",
    "            # Scale keypoints\n",
    "            person_keypoints_scaled = scaler.transform([person_keypoints])\n",
    "\n",
    "            # Convert to tensor\n",
    "            input_tensor = torch.tensor(person_keypoints_scaled, dtype=torch.float32)\n",
    "\n",
    "            # Predict\n",
    "            with torch.no_grad():\n",
    "                output = model(input_tensor)\n",
    "                _, predicted_class = torch.max(output, 1)\n",
    "\n",
    "            # Map prediction\n",
    "            label = 'Correct' if predicted_class.item() == 1 else 'Wrong'\n",
    "\n",
    "            # Display result on frame\n",
    "            color = (0, 255, 0) if label == 'Correct' else (0, 0, 255)\n",
    "            cv2.putText(frame, label, (30, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.5, color, 3)\n",
    "\n",
    "    # Show frame\n",
    "    cv2.imshow('Live Squat Form Prediction', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "511d0ca2-00d7-4d7e-8d6d-8b2b7aec7b12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7832e5d-08b6-451d-b0a8-b4147b8211ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39c05aee-cd64-4c55-a549-4535ddfd5f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "# Load CSV\n",
    "df = pd.read_csv(r\"C:\\Users\\Kassimi\\OneDrive\\Bureau\\cv_data\\squat\\squat_pose_data.csv\")\n",
    "\n",
    "# Convert label to numeric\n",
    "df['label'] = df['label'].map({'correct_form': 1, 'wrong_form': 0})\n",
    "\n",
    "# Parameters\n",
    "sequence_length = 30  # Choose fixed sequence length\n",
    "min_frames_required = sequence_length\n",
    "\n",
    "# Normalize keypoints\n",
    "keypoint_cols = [col for col in df.columns if col.startswith('kp_')]\n",
    "scaler = StandardScaler()\n",
    "df[keypoint_cols] = scaler.fit_transform(df[keypoint_cols])\n",
    "\n",
    "# Group by video and build sequences\n",
    "X_sequences = []\n",
    "y_labels = []\n",
    "\n",
    "for video_id, group in df.groupby('video_id'):\n",
    "    group = group.sort_values('frame')\n",
    "    keypoints = group[keypoint_cols].values  # shape: (num_frames, 34)\n",
    "    label = group['label'].iloc[0]\n",
    "\n",
    "    # Skip short sequences\n",
    "    if len(keypoints) < min_frames_required:\n",
    "        continue\n",
    "\n",
    "    # Break long videos into multiple sequences\n",
    "    for start in range(0, len(keypoints) - sequence_length + 1, sequence_length):\n",
    "        seq = keypoints[start:start + sequence_length]\n",
    "        X_sequences.append(seq)\n",
    "        y_labels.append(label)\n",
    "\n",
    "# Convert to tensors\n",
    "\n",
    "\n",
    "X_tensor = torch.tensor(np.array(X_sequences), dtype=torch.float32)\n",
    " # shape: (N, seq_len, 34)\n",
    "y_tensor = torch.tensor(y_labels, dtype=torch.long)\n",
    "\n",
    "# Train/val split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_tensor, y_tensor, test_size=0.2, random_state=42)\n",
    "\n",
    "# PyTorch Dataset\n",
    "class SquatSequenceDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# Dataloaders\n",
    "train_dataset = SquatSequenceDataset(X_train, y_train)\n",
    "val_dataset = SquatSequenceDataset(X_val, y_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1df01e66-1828-4597-b86d-3b9635f36e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class SquatNetLSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SquatNetLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=34, hidden_size=64, num_layers=2, batch_first=True)\n",
    "        self.fc1 = nn.Linear(64, 64)  # LSTM output to hidden layer\n",
    "        self.fc2 = nn.Linear(64, 1)   \n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, sequence_length, 34)\n",
    "        lstm_out, _ = self.lstm(x)              # Output shape: (batch_size, sequence_length, hidden_size)\n",
    "        x = lstm_out[:, -1, :]                  # Take output from the last time step\n",
    "        x = self.relu(self.fc1(x))              # Pass through FC layer\n",
    "        x = self.fc2(x)                         # Output layer\n",
    "        return self.sigmoid(x)                  # Softmax for probabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "561c5c8b-f5ea-40f7-8b92-5fcfae548322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100] Train Loss: 0.5401, Train Acc: 0.8172 | Val Loss: 0.4424, Val Acc: 0.8333\n",
      "Epoch [2/100] Train Loss: 0.4361, Train Acc: 0.8172 | Val Loss: 0.4065, Val Acc: 0.8333\n",
      "Epoch [3/100] Train Loss: 0.4326, Train Acc: 0.8172 | Val Loss: 0.3929, Val Acc: 0.8333\n",
      "Epoch [4/100] Train Loss: 0.4117, Train Acc: 0.8172 | Val Loss: 0.3767, Val Acc: 0.8333\n",
      "Epoch [5/100] Train Loss: 0.4094, Train Acc: 0.8172 | Val Loss: 0.3767, Val Acc: 0.8333\n",
      "Epoch [6/100] Train Loss: 0.4028, Train Acc: 0.8172 | Val Loss: 0.3769, Val Acc: 0.8333\n",
      "Epoch [7/100] Train Loss: 0.4028, Train Acc: 0.8172 | Val Loss: 0.3774, Val Acc: 0.8333\n",
      "Epoch [8/100] Train Loss: 0.4094, Train Acc: 0.8172 | Val Loss: 0.3811, Val Acc: 0.8333\n",
      "Epoch [9/100] Train Loss: 0.4094, Train Acc: 0.8172 | Val Loss: 0.4055, Val Acc: 0.8333\n",
      "Epoch [10/100] Train Loss: 0.4134, Train Acc: 0.8710 | Val Loss: 0.3847, Val Acc: 0.9167\n",
      "Epoch [11/100] Train Loss: 0.4094, Train Acc: 0.8925 | Val Loss: 0.3876, Val Acc: 0.9167\n",
      "Epoch [12/100] Train Loss: 0.4360, Train Acc: 0.8710 | Val Loss: 0.3879, Val Acc: 0.9167\n",
      "Epoch [13/100] Train Loss: 0.4361, Train Acc: 0.8710 | Val Loss: 0.3775, Val Acc: 0.9167\n",
      "Epoch [14/100] Train Loss: 0.4227, Train Acc: 0.9032 | Val Loss: 0.3766, Val Acc: 0.9167\n",
      "Epoch [15/100] Train Loss: 0.4027, Train Acc: 0.9247 | Val Loss: 0.3766, Val Acc: 0.9167\n",
      "Epoch [16/100] Train Loss: 0.4027, Train Acc: 0.9247 | Val Loss: 0.3766, Val Acc: 0.9167\n",
      "Epoch [17/100] Train Loss: 0.4068, Train Acc: 0.9247 | Val Loss: 0.3768, Val Acc: 0.9167\n",
      "Epoch [18/100] Train Loss: 0.4068, Train Acc: 0.9247 | Val Loss: 0.3924, Val Acc: 0.9167\n",
      "Epoch [19/100] Train Loss: 0.4068, Train Acc: 0.9140 | Val Loss: 0.3924, Val Acc: 0.9167\n",
      "Epoch [20/100] Train Loss: 0.4068, Train Acc: 0.9140 | Val Loss: 0.3924, Val Acc: 0.8750\n",
      "Epoch [21/100] Train Loss: 0.4068, Train Acc: 0.9140 | Val Loss: 0.3924, Val Acc: 0.8750\n",
      "Epoch [22/100] Train Loss: 0.4068, Train Acc: 0.9140 | Val Loss: 0.3924, Val Acc: 0.8750\n",
      "Epoch [23/100] Train Loss: 0.4068, Train Acc: 0.9140 | Val Loss: 0.3924, Val Acc: 0.8750\n",
      "Epoch [24/100] Train Loss: 0.4068, Train Acc: 0.9140 | Val Loss: 0.3924, Val Acc: 0.8750\n",
      "Epoch [25/100] Train Loss: 0.4068, Train Acc: 0.9140 | Val Loss: 0.3924, Val Acc: 0.8750\n",
      "Epoch [26/100] Train Loss: 0.4068, Train Acc: 0.9140 | Val Loss: 0.3924, Val Acc: 0.8750\n",
      "Epoch [27/100] Train Loss: 0.4068, Train Acc: 0.9140 | Val Loss: 0.3924, Val Acc: 0.8750\n",
      "Epoch [28/100] Train Loss: 0.4068, Train Acc: 0.9140 | Val Loss: 0.3924, Val Acc: 0.8750\n",
      "Epoch [29/100] Train Loss: 0.4068, Train Acc: 0.9140 | Val Loss: 0.3924, Val Acc: 0.8750\n",
      "Epoch [30/100] Train Loss: 0.4068, Train Acc: 0.9140 | Val Loss: 0.3924, Val Acc: 0.8750\n",
      "Epoch [31/100] Train Loss: 0.4068, Train Acc: 0.9140 | Val Loss: 0.3924, Val Acc: 0.8750\n",
      "Epoch [32/100] Train Loss: 0.4068, Train Acc: 0.9140 | Val Loss: 0.3924, Val Acc: 0.8750\n",
      "Epoch [33/100] Train Loss: 0.4068, Train Acc: 0.9140 | Val Loss: 0.3924, Val Acc: 0.8750\n",
      "Epoch [34/100] Train Loss: 0.4068, Train Acc: 0.9140 | Val Loss: 0.3924, Val Acc: 0.8750\n",
      "Epoch [35/100] Train Loss: 0.4068, Train Acc: 0.9140 | Val Loss: 0.3924, Val Acc: 0.8750\n",
      "Epoch [36/100] Train Loss: 0.4068, Train Acc: 0.9140 | Val Loss: 0.3924, Val Acc: 0.8750\n",
      "Epoch [37/100] Train Loss: 0.4068, Train Acc: 0.9140 | Val Loss: 0.3924, Val Acc: 0.8750\n",
      "Epoch [38/100] Train Loss: 0.4068, Train Acc: 0.9140 | Val Loss: 0.3924, Val Acc: 0.8750\n",
      "Epoch [39/100] Train Loss: 0.4068, Train Acc: 0.9140 | Val Loss: 0.3924, Val Acc: 0.8750\n",
      "Epoch [40/100] Train Loss: 0.4068, Train Acc: 0.9247 | Val Loss: 0.3924, Val Acc: 0.8750\n",
      "Epoch [41/100] Train Loss: 0.4068, Train Acc: 0.9247 | Val Loss: 0.3924, Val Acc: 0.8750\n",
      "Epoch [42/100] Train Loss: 0.4068, Train Acc: 0.9247 | Val Loss: 0.3924, Val Acc: 0.8750\n",
      "Epoch [43/100] Train Loss: 0.4068, Train Acc: 0.9247 | Val Loss: 0.3924, Val Acc: 0.8750\n",
      "Epoch [44/100] Train Loss: 0.4068, Train Acc: 0.9247 | Val Loss: 0.3924, Val Acc: 0.8750\n",
      "Epoch [45/100] Train Loss: 0.4068, Train Acc: 0.9355 | Val Loss: 0.3924, Val Acc: 0.8750\n",
      "Epoch [46/100] Train Loss: 0.4068, Train Acc: 0.9355 | Val Loss: 0.3924, Val Acc: 0.8750\n",
      "Epoch [47/100] Train Loss: 0.4068, Train Acc: 0.9355 | Val Loss: 0.3924, Val Acc: 0.8750\n",
      "Epoch [48/100] Train Loss: 0.4068, Train Acc: 0.9355 | Val Loss: 0.3924, Val Acc: 0.8750\n",
      "Epoch [49/100] Train Loss: 0.4068, Train Acc: 0.9355 | Val Loss: 0.3924, Val Acc: 0.8750\n",
      "Epoch [50/100] Train Loss: 0.4068, Train Acc: 0.9355 | Val Loss: 0.3924, Val Acc: 0.8750\n",
      "Epoch [51/100] Train Loss: 0.4068, Train Acc: 0.9355 | Val Loss: 0.3924, Val Acc: 0.8750\n",
      "Epoch [52/100] Train Loss: 0.4068, Train Acc: 0.9355 | Val Loss: 0.3924, Val Acc: 0.8750\n",
      "Epoch [53/100] Train Loss: 0.4068, Train Acc: 0.9355 | Val Loss: 0.3924, Val Acc: 0.8750\n",
      "Epoch [54/100] Train Loss: 0.4068, Train Acc: 0.9355 | Val Loss: 0.3924, Val Acc: 0.8750\n",
      "Epoch [55/100] Train Loss: 0.4068, Train Acc: 0.9355 | Val Loss: 0.3924, Val Acc: 0.8750\n",
      "Epoch [56/100] Train Loss: 0.4068, Train Acc: 0.9355 | Val Loss: 0.3924, Val Acc: 0.8750\n",
      "Epoch [57/100] Train Loss: 0.4068, Train Acc: 0.9462 | Val Loss: 0.3924, Val Acc: 0.8750\n",
      "Epoch [58/100] Train Loss: 0.4068, Train Acc: 0.9462 | Val Loss: 0.3924, Val Acc: 0.9167\n",
      "Epoch [59/100] Train Loss: 0.4068, Train Acc: 0.9462 | Val Loss: 0.3924, Val Acc: 0.9167\n",
      "Epoch [60/100] Train Loss: 0.4068, Train Acc: 0.9462 | Val Loss: 0.3924, Val Acc: 0.9167\n",
      "Epoch [61/100] Train Loss: 0.4068, Train Acc: 0.9462 | Val Loss: 0.3924, Val Acc: 0.9167\n",
      "Epoch [62/100] Train Loss: 0.4068, Train Acc: 0.9462 | Val Loss: 0.3924, Val Acc: 0.9167\n",
      "Epoch [63/100] Train Loss: 0.4068, Train Acc: 0.9570 | Val Loss: 0.3924, Val Acc: 0.9167\n",
      "Epoch [64/100] Train Loss: 0.4068, Train Acc: 0.9570 | Val Loss: 0.3924, Val Acc: 0.9167\n",
      "Epoch [65/100] Train Loss: 0.4068, Train Acc: 0.9570 | Val Loss: 0.3924, Val Acc: 0.9167\n",
      "Epoch [66/100] Train Loss: 0.4068, Train Acc: 0.9570 | Val Loss: 0.3924, Val Acc: 0.9167\n",
      "Epoch [67/100] Train Loss: 0.4068, Train Acc: 0.9570 | Val Loss: 0.3924, Val Acc: 0.9167\n",
      "Epoch [68/100] Train Loss: 0.4068, Train Acc: 0.9570 | Val Loss: 0.3924, Val Acc: 0.9167\n",
      "Epoch [69/100] Train Loss: 0.4068, Train Acc: 0.9570 | Val Loss: 0.3924, Val Acc: 0.9167\n",
      "Epoch [70/100] Train Loss: 0.4068, Train Acc: 0.9570 | Val Loss: 0.3924, Val Acc: 0.9167\n",
      "Epoch [71/100] Train Loss: 0.4068, Train Acc: 0.9570 | Val Loss: 0.3924, Val Acc: 0.9167\n",
      "Epoch [72/100] Train Loss: 0.4068, Train Acc: 0.9570 | Val Loss: 0.3924, Val Acc: 0.9167\n",
      "Epoch [73/100] Train Loss: 0.4068, Train Acc: 0.9570 | Val Loss: 0.3924, Val Acc: 0.9167\n",
      "Epoch [74/100] Train Loss: 0.4068, Train Acc: 0.9570 | Val Loss: 0.3924, Val Acc: 0.9167\n",
      "Epoch [75/100] Train Loss: 0.4068, Train Acc: 0.9570 | Val Loss: 0.3924, Val Acc: 0.9167\n",
      "Epoch [76/100] Train Loss: 0.4068, Train Acc: 0.9570 | Val Loss: 0.3924, Val Acc: 0.9167\n",
      "Epoch [77/100] Train Loss: 0.4068, Train Acc: 0.9570 | Val Loss: 0.3924, Val Acc: 0.9167\n",
      "Epoch [78/100] Train Loss: 0.4068, Train Acc: 0.9570 | Val Loss: 0.3924, Val Acc: 0.9167\n",
      "Epoch [79/100] Train Loss: 0.4068, Train Acc: 0.9570 | Val Loss: 0.3924, Val Acc: 0.9167\n",
      "Epoch [80/100] Train Loss: 0.4068, Train Acc: 0.9570 | Val Loss: 0.3924, Val Acc: 0.9167\n",
      "Epoch [81/100] Train Loss: 0.4068, Train Acc: 0.9570 | Val Loss: 0.3924, Val Acc: 0.9167\n",
      "Epoch [82/100] Train Loss: 0.4068, Train Acc: 0.9570 | Val Loss: 0.3924, Val Acc: 0.9167\n",
      "Epoch [83/100] Train Loss: 0.4068, Train Acc: 0.9570 | Val Loss: 0.3924, Val Acc: 0.9167\n",
      "Epoch [84/100] Train Loss: 0.4068, Train Acc: 0.9570 | Val Loss: 0.3924, Val Acc: 0.9167\n",
      "Epoch [85/100] Train Loss: 0.4068, Train Acc: 0.9570 | Val Loss: 0.3924, Val Acc: 0.9167\n",
      "Epoch [86/100] Train Loss: 0.4068, Train Acc: 0.9570 | Val Loss: 0.3924, Val Acc: 0.9167\n",
      "Epoch [87/100] Train Loss: 0.4068, Train Acc: 0.9570 | Val Loss: 0.3924, Val Acc: 0.9167\n",
      "Epoch [88/100] Train Loss: 0.4068, Train Acc: 0.9570 | Val Loss: 0.3924, Val Acc: 0.9167\n",
      "Epoch [89/100] Train Loss: 0.4068, Train Acc: 0.9570 | Val Loss: 0.3924, Val Acc: 0.9167\n",
      "Epoch [90/100] Train Loss: 0.4068, Train Acc: 0.9570 | Val Loss: 0.3924, Val Acc: 0.9167\n",
      "Epoch [91/100] Train Loss: 0.4068, Train Acc: 0.9570 | Val Loss: 0.3924, Val Acc: 0.9167\n",
      "Epoch [92/100] Train Loss: 0.4068, Train Acc: 0.9570 | Val Loss: 0.3924, Val Acc: 0.9167\n",
      "Epoch [93/100] Train Loss: 0.4068, Train Acc: 0.9570 | Val Loss: 0.3924, Val Acc: 0.9167\n",
      "Epoch [94/100] Train Loss: 0.4068, Train Acc: 0.9570 | Val Loss: 0.3924, Val Acc: 0.9167\n",
      "Epoch [95/100] Train Loss: 0.4068, Train Acc: 0.9570 | Val Loss: 0.3924, Val Acc: 0.9167\n",
      "Epoch [96/100] Train Loss: 0.4068, Train Acc: 0.9570 | Val Loss: 0.3924, Val Acc: 0.9167\n",
      "Epoch [97/100] Train Loss: 0.4068, Train Acc: 0.9570 | Val Loss: 0.3924, Val Acc: 0.9167\n",
      "Epoch [98/100] Train Loss: 0.4068, Train Acc: 0.9570 | Val Loss: 0.3924, Val Acc: 0.9167\n",
      "Epoch [99/100] Train Loss: 0.4068, Train Acc: 0.9570 | Val Loss: 0.3924, Val Acc: 0.9167\n",
      "Epoch [100/100] Train Loss: 0.4068, Train Acc: 0.9570 | Val Loss: 0.3924, Val Acc: 0.9167\n"
     ]
    }
   ],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = SquatNetLSTM().to(device)\n",
    "\n",
    "# Use BCEWithLogitsLoss for binary classification\n",
    "criterion = nn.BCEWithLogitsLoss()  # This combines sigmoid and binary cross-entropy\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs.squeeze(), labels.float())  # Ensure labels are of shape (batch_size,)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "        predicted = (torch.sigmoid(outputs) > 0.5).float()  # Convert logits to binary predictions\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted.squeeze() == labels).sum().item()\n",
    "\n",
    "    avg_train_loss = train_loss / total\n",
    "    train_acc = correct / total\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs.squeeze(), labels.float())\n",
    "\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "            predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted.squeeze() == labels).sum().item()\n",
    "\n",
    "    avg_val_loss = val_loss / total\n",
    "    val_acc = correct / total\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] \"\n",
    "          f\"Train Loss: {avg_train_loss:.4f}, Train Acc: {train_acc:.4f} | \"\n",
    "          f\"Val Loss: {avg_val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "912a268f-e255-4047-af35-681538e2f30e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Model saved to C:\\Users\\Kassimi\\OneDrive\\Bureau\\cv_data\\squat_lstm_model.pth\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model\n",
    "model_path = r\"C:\\Users\\Kassimi\\OneDrive\\Bureau\\cv_data\\squat_lstm_model.pth\"\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print(f\" Model saved to {model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eef073e4-45fb-4b98-acbd-85f8bc77ffa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\AppData\\Local\\Temp\\ipykernel_19820\\3973820042.py:55: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:257.)\n",
      "  input_seq = torch.tensor([list(sequence_buffer)], dtype=torch.float32)  # Shape: (1, seq_len, 34)\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import deque\n",
    "\n",
    "# LSTM sequence length\n",
    "sequence_length = 30\n",
    "\n",
    "# Load trained model\n",
    "model = SquatNetLSTM()\n",
    "model.load_state_dict(torch.load(r'C:\\Users\\Kassimi\\OneDrive\\Bureau\\cv_data\\squat_lstm_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "# Load scaler (refit on original dataset)\n",
    "df = pd.read_csv(r\"C:\\Users\\Kassimi\\OneDrive\\Bureau\\cv_data\\squat\\squat_pose_data.csv\")\n",
    "keypoint_cols = [col for col in df.columns if col.startswith('kp_')]\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df[keypoint_cols])  # Fit only on keypoints\n",
    "\n",
    "# Load YOLO pose model\n",
    "yolo_model = YOLO('yolov8n-pose.pt')\n",
    "\n",
    "# Video path\n",
    "video_path = r\"C:\\Users\\Kassimi\\OneDrive\\Bureau\\cv_data\\squat\\preprocessed\\wrong\\wrong_4_augmented_6.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Buffer to store sequence of keypoints\n",
    "sequence_buffer = deque(maxlen=sequence_length)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    results = yolo_model.predict(frame, save=False, verbose=False)\n",
    "    keypoints = results[0].keypoints.xy.cpu().numpy()\n",
    "\n",
    "    if len(keypoints) == 0:\n",
    "        continue\n",
    "\n",
    "    person_keypoints = keypoints[0].flatten()\n",
    "\n",
    "    if len(person_keypoints) != 34:\n",
    "        continue\n",
    "\n",
    "    # Scale keypoints\n",
    "    person_keypoints_scaled = scaler.transform([person_keypoints])[0]\n",
    "    sequence_buffer.append(person_keypoints_scaled)\n",
    "\n",
    "    # Only predict when we have a full sequence\n",
    "    if len(sequence_buffer) == sequence_length:\n",
    "        input_seq = torch.tensor([list(sequence_buffer)], dtype=torch.float32)  # Shape: (1, seq_len, 34)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(input_seq)\n",
    "            _, predicted_class = torch.max(output, 1)\n",
    "\n",
    "        label = 'Correct' if predicted_class.item() == 1 else 'Wrong'\n",
    "        color = (0, 255, 0) if label == 'Correct' else (0, 0, 255)\n",
    "\n",
    "        cv2.putText(frame, label, (30, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.5, color, 3)\n",
    "\n",
    "    cv2.imshow('Squat Form Prediction', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6ad037f2-6caa-4df5-b30b-13cb4303da7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "# Set model to eval mode\n",
    "model.eval()\n",
    "\n",
    "# Collect all predictions and labels\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in val_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Wrong', 'Correct'])\n",
    "\n",
    "# Plot\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title(\"Confusion Matrix - Squat Form Classification\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ad1ebead-3612-4ee6-b231-57ec97def0b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of frames per video:\n",
      "video_id\n",
      "correct_1.mp4     173\n",
      "correct_10.mp4    782\n",
      "correct_11.mp4    146\n",
      "correct_12.mp4    173\n",
      "correct_2.mp4     244\n",
      "correct_3.mp4     391\n",
      "correct_5.mp4      53\n",
      "correct_6.mp4     373\n",
      "correct_7.mp4     314\n",
      "correct_8.mp4     195\n",
      "correct_9.mp4     195\n",
      "wrong_1.mp4        70\n",
      "wrong_2.mp4        52\n",
      "wrong_3.mp4        29\n",
      "wrong_4.mp4       195\n",
      "wrong_5.mp4       195\n",
      "wrong_6.mp4       197\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV with keypoints and video data\n",
    "df = pd.read_csv(r\"C:\\Users\\Kassimi\\OneDrive\\Bureau\\cv_data\\squat\\squat_pose_data.csv\")\n",
    "\n",
    "# Count number of frames for each video\n",
    "frame_counts = df.groupby('video_id').size()\n",
    "\n",
    "# Print the number of frames per video\n",
    "print(\"Number of frames per video:\")\n",
    "print(frame_counts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

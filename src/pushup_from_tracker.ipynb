{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "192cb734-c242-498b-9694-7b521918154f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¥ Augmenting and saving videos...\n",
      "âœ… Augmented videos saved.\n",
      "\n",
      "ðŸ“¸ Extracting frames and pose keypoints...\n",
      "âœ… Keypoints from all videos (original + augmented) saved to: C:/Users/Kassimi/OneDrive/Bureau/cv_data/pushups\\pushup_pose_data.csv\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Load YOLOv8n-pose model\n",
    "model = YOLO('yolov8n-pose.pt')\n",
    "\n",
    "# Paths\n",
    "data_root = r'C:/Users/Kassimi/OneDrive/Bureau/cv_data/pushups'\n",
    "folders = ['correct sequence', 'wrong sequence']\n",
    "augmented_folders = {'correct sequence': 'aug_correct', 'wrong sequence': 'aug_wrong'}\n",
    "\n",
    "# Create folders for augmented videos\n",
    "for folder in augmented_folders.values():\n",
    "    os.makedirs(os.path.join(data_root, folder), exist_ok=True)\n",
    "\n",
    "# Augmentation function\n",
    "def augment_frame(frame):\n",
    "    if random.random() < 0.5:\n",
    "        frame = cv2.flip(frame, 1)  # Horizontal flip\n",
    "    alpha = random.uniform(0.8, 1.2)  # Contrast\n",
    "    beta = random.randint(-30, 30)   # Brightness\n",
    "    frame = cv2.convertScaleAbs(frame, alpha=alpha, beta=beta)\n",
    "    return frame\n",
    "\n",
    "#  Create augmented videos\n",
    "print(\"ðŸŽ¥ Augmenting and saving videos...\")\n",
    "for label in folders:\n",
    "    input_folder = os.path.join(data_root, label)\n",
    "    output_folder = os.path.join(data_root, augmented_folders[label])\n",
    "\n",
    "    for video_file in os.listdir(input_folder):\n",
    "        if not video_file.endswith(('.mp4', '.avi', '.mov')):\n",
    "            continue\n",
    "\n",
    "        input_path = os.path.join(input_folder, video_file)\n",
    "        output_path = os.path.join(output_folder, f\"aug_{video_file}\")\n",
    "\n",
    "        cap = cv2.VideoCapture(input_path)\n",
    "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            aug_frame = augment_frame(frame)\n",
    "            out.write(aug_frame)\n",
    "\n",
    "        cap.release()\n",
    "        out.release()\n",
    "\n",
    "print(\"âœ… Augmented videos saved.\\n\")\n",
    "\n",
    "#  Extract frames and keypoints from both original and augmented videos\n",
    "print(\"ðŸ“¸ Extracting frames and pose keypoints...\")\n",
    "\n",
    "output_data = []\n",
    "\n",
    "# Process both original and augmented videos\n",
    "for label in folders + list(augmented_folders.values()):  # Including augmented folders\n",
    "    folder_path = os.path.join(data_root, label)\n",
    "\n",
    "    for video_file in os.listdir(folder_path):\n",
    "        if not video_file.endswith(('.mp4', '.avi', '.mov')):\n",
    "            continue\n",
    "\n",
    "        video_path = os.path.join(folder_path, video_file)\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        frame_index = 0\n",
    "\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # Pose estimation\n",
    "            results = model.predict(frame, save=False, verbose=False)\n",
    "            keypoints = results[0].keypoints.xy.cpu().numpy()\n",
    "\n",
    "            if len(keypoints) == 0:\n",
    "                frame_index += 1\n",
    "                continue\n",
    "\n",
    "            # Take only the first person detected\n",
    "            person_keypoints = keypoints[0].flatten()  # shape: (34,)\n",
    "            row = [video_file, frame_index] + list(person_keypoints) + [label]\n",
    "            output_data.append(row)\n",
    "\n",
    "            frame_index += 1\n",
    "        cap.release()\n",
    "\n",
    "# Save to CSV\n",
    "columns = ['video_id', 'frame'] + [f'kp_{i}_{coord}' for i in range(17) for coord in ['x', 'y']] + ['label']\n",
    "df = pd.DataFrame(output_data, columns=columns)\n",
    "\n",
    "output_csv_path = os.path.join(data_root, 'pushup_pose_data.csv')\n",
    "df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f\"âœ… Keypoints from all videos (original + augmented) saved to: {output_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "97a92bbd-9113-4e31-be86-20cb5de2f5f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>frame</th>\n",
       "      <th>kp_0_x</th>\n",
       "      <th>kp_0_y</th>\n",
       "      <th>kp_1_x</th>\n",
       "      <th>kp_1_y</th>\n",
       "      <th>kp_2_x</th>\n",
       "      <th>kp_2_y</th>\n",
       "      <th>kp_3_x</th>\n",
       "      <th>kp_3_y</th>\n",
       "      <th>...</th>\n",
       "      <th>kp_12_y</th>\n",
       "      <th>kp_13_x</th>\n",
       "      <th>kp_13_y</th>\n",
       "      <th>kp_14_x</th>\n",
       "      <th>kp_14_y</th>\n",
       "      <th>kp_15_x</th>\n",
       "      <th>kp_15_y</th>\n",
       "      <th>kp_16_x</th>\n",
       "      <th>kp_16_y</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Copy of push up 1.mp4</td>\n",
       "      <td>0</td>\n",
       "      <td>470.29395</td>\n",
       "      <td>210.786789</td>\n",
       "      <td>474.699005</td>\n",
       "      <td>205.294525</td>\n",
       "      <td>471.992767</td>\n",
       "      <td>199.126373</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>158.329926</td>\n",
       "      <td>164.350677</td>\n",
       "      <td>236.564285</td>\n",
       "      <td>167.065247</td>\n",
       "      <td>222.115448</td>\n",
       "      <td>19.154755</td>\n",
       "      <td>285.743134</td>\n",
       "      <td>24.524994</td>\n",
       "      <td>281.398132</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Copy of push up 1.mp4</td>\n",
       "      <td>1</td>\n",
       "      <td>470.05493</td>\n",
       "      <td>210.226105</td>\n",
       "      <td>475.933716</td>\n",
       "      <td>204.226776</td>\n",
       "      <td>471.986908</td>\n",
       "      <td>195.307053</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>148.483047</td>\n",
       "      <td>174.185471</td>\n",
       "      <td>246.092224</td>\n",
       "      <td>174.133942</td>\n",
       "      <td>216.902008</td>\n",
       "      <td>37.519714</td>\n",
       "      <td>308.267334</td>\n",
       "      <td>40.383118</td>\n",
       "      <td>285.514893</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Copy of push up 1.mp4</td>\n",
       "      <td>2</td>\n",
       "      <td>470.19278</td>\n",
       "      <td>212.633636</td>\n",
       "      <td>475.442169</td>\n",
       "      <td>206.140823</td>\n",
       "      <td>471.920502</td>\n",
       "      <td>198.019073</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>152.222107</td>\n",
       "      <td>171.839996</td>\n",
       "      <td>247.033997</td>\n",
       "      <td>172.521240</td>\n",
       "      <td>219.902557</td>\n",
       "      <td>33.059113</td>\n",
       "      <td>308.396637</td>\n",
       "      <td>36.110382</td>\n",
       "      <td>287.430023</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Copy of push up 1.mp4</td>\n",
       "      <td>3</td>\n",
       "      <td>470.89636</td>\n",
       "      <td>212.662811</td>\n",
       "      <td>476.404419</td>\n",
       "      <td>206.303314</td>\n",
       "      <td>472.506042</td>\n",
       "      <td>198.065811</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>153.436523</td>\n",
       "      <td>170.993851</td>\n",
       "      <td>247.762726</td>\n",
       "      <td>170.518173</td>\n",
       "      <td>220.252960</td>\n",
       "      <td>30.347168</td>\n",
       "      <td>306.387878</td>\n",
       "      <td>33.768555</td>\n",
       "      <td>285.480804</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Copy of push up 1.mp4</td>\n",
       "      <td>4</td>\n",
       "      <td>471.8687</td>\n",
       "      <td>210.240173</td>\n",
       "      <td>478.258026</td>\n",
       "      <td>203.996674</td>\n",
       "      <td>472.973633</td>\n",
       "      <td>194.745804</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>152.613342</td>\n",
       "      <td>175.539963</td>\n",
       "      <td>247.787415</td>\n",
       "      <td>173.467041</td>\n",
       "      <td>216.459595</td>\n",
       "      <td>31.727356</td>\n",
       "      <td>309.895935</td>\n",
       "      <td>34.773468</td>\n",
       "      <td>284.468719</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20635</th>\n",
       "      <td>aug_Copy of push up 81.mp4</td>\n",
       "      <td>88</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>195.980637</td>\n",
       "      <td>220.386139</td>\n",
       "      <td>231.456543</td>\n",
       "      <td>225.815903</td>\n",
       "      <td>228.070755</td>\n",
       "      <td>80.811462</td>\n",
       "      <td>200.456619</td>\n",
       "      <td>84.838776</td>\n",
       "      <td>201.392670</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20636</th>\n",
       "      <td>aug_Copy of push up 81.mp4</td>\n",
       "      <td>89</td>\n",
       "      <td>101.722916</td>\n",
       "      <td>99.781471</td>\n",
       "      <td>106.058823</td>\n",
       "      <td>86.640907</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>130.515030</td>\n",
       "      <td>79.025879</td>\n",
       "      <td>...</td>\n",
       "      <td>208.271088</td>\n",
       "      <td>421.723450</td>\n",
       "      <td>197.422852</td>\n",
       "      <td>411.472290</td>\n",
       "      <td>223.376602</td>\n",
       "      <td>535.454224</td>\n",
       "      <td>206.514099</td>\n",
       "      <td>528.744141</td>\n",
       "      <td>229.306793</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20637</th>\n",
       "      <td>aug_Copy of push up 81.mp4</td>\n",
       "      <td>90</td>\n",
       "      <td>100.9666</td>\n",
       "      <td>100.084717</td>\n",
       "      <td>105.165054</td>\n",
       "      <td>86.992126</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>128.998245</td>\n",
       "      <td>78.785080</td>\n",
       "      <td>...</td>\n",
       "      <td>208.689301</td>\n",
       "      <td>416.601562</td>\n",
       "      <td>195.951431</td>\n",
       "      <td>405.537598</td>\n",
       "      <td>218.852554</td>\n",
       "      <td>535.146179</td>\n",
       "      <td>211.927536</td>\n",
       "      <td>527.344360</td>\n",
       "      <td>230.922729</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20638</th>\n",
       "      <td>aug_Copy of push up 81.mp4</td>\n",
       "      <td>91</td>\n",
       "      <td>103.80043</td>\n",
       "      <td>100.658356</td>\n",
       "      <td>106.407501</td>\n",
       "      <td>87.300125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>128.524185</td>\n",
       "      <td>78.168808</td>\n",
       "      <td>...</td>\n",
       "      <td>208.099899</td>\n",
       "      <td>429.433807</td>\n",
       "      <td>204.062317</td>\n",
       "      <td>418.362305</td>\n",
       "      <td>222.913101</td>\n",
       "      <td>545.697693</td>\n",
       "      <td>217.271606</td>\n",
       "      <td>531.541016</td>\n",
       "      <td>228.716782</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20639</th>\n",
       "      <td>aug_Copy of push up 81.mp4</td>\n",
       "      <td>92</td>\n",
       "      <td>101.64122</td>\n",
       "      <td>99.620522</td>\n",
       "      <td>105.246185</td>\n",
       "      <td>87.131210</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>128.815918</td>\n",
       "      <td>79.782578</td>\n",
       "      <td>...</td>\n",
       "      <td>210.797607</td>\n",
       "      <td>428.307312</td>\n",
       "      <td>192.335968</td>\n",
       "      <td>415.217468</td>\n",
       "      <td>217.114029</td>\n",
       "      <td>540.293518</td>\n",
       "      <td>207.061066</td>\n",
       "      <td>530.577271</td>\n",
       "      <td>228.462601</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20640 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         video_id  frame      kp_0_x      kp_0_y      kp_1_x  \\\n",
       "0           Copy of push up 1.mp4      0   470.29395  210.786789  474.699005   \n",
       "1           Copy of push up 1.mp4      1   470.05493  210.226105  475.933716   \n",
       "2           Copy of push up 1.mp4      2   470.19278  212.633636  475.442169   \n",
       "3           Copy of push up 1.mp4      3   470.89636  212.662811  476.404419   \n",
       "4           Copy of push up 1.mp4      4    471.8687  210.240173  478.258026   \n",
       "...                           ...    ...         ...         ...         ...   \n",
       "20635  aug_Copy of push up 81.mp4     88         0.0    0.000000    0.000000   \n",
       "20636  aug_Copy of push up 81.mp4     89  101.722916   99.781471  106.058823   \n",
       "20637  aug_Copy of push up 81.mp4     90    100.9666  100.084717  105.165054   \n",
       "20638  aug_Copy of push up 81.mp4     91   103.80043  100.658356  106.407501   \n",
       "20639  aug_Copy of push up 81.mp4     92   101.64122   99.620522  105.246185   \n",
       "\n",
       "           kp_1_y      kp_2_x      kp_2_y      kp_3_x     kp_3_y  ...  \\\n",
       "0      205.294525  471.992767  199.126373    0.000000   0.000000  ...   \n",
       "1      204.226776  471.986908  195.307053    0.000000   0.000000  ...   \n",
       "2      206.140823  471.920502  198.019073    0.000000   0.000000  ...   \n",
       "3      206.303314  472.506042  198.065811    0.000000   0.000000  ...   \n",
       "4      203.996674  472.973633  194.745804    0.000000   0.000000  ...   \n",
       "...           ...         ...         ...         ...        ...  ...   \n",
       "20635    0.000000    0.000000    0.000000    0.000000   0.000000  ...   \n",
       "20636   86.640907    0.000000    0.000000  130.515030  79.025879  ...   \n",
       "20637   86.992126    0.000000    0.000000  128.998245  78.785080  ...   \n",
       "20638   87.300125    0.000000    0.000000  128.524185  78.168808  ...   \n",
       "20639   87.131210    0.000000    0.000000  128.815918  79.782578  ...   \n",
       "\n",
       "          kp_12_y     kp_13_x     kp_13_y     kp_14_x     kp_14_y     kp_15_x  \\\n",
       "0      158.329926  164.350677  236.564285  167.065247  222.115448   19.154755   \n",
       "1      148.483047  174.185471  246.092224  174.133942  216.902008   37.519714   \n",
       "2      152.222107  171.839996  247.033997  172.521240  219.902557   33.059113   \n",
       "3      153.436523  170.993851  247.762726  170.518173  220.252960   30.347168   \n",
       "4      152.613342  175.539963  247.787415  173.467041  216.459595   31.727356   \n",
       "...           ...         ...         ...         ...         ...         ...   \n",
       "20635  195.980637  220.386139  231.456543  225.815903  228.070755   80.811462   \n",
       "20636  208.271088  421.723450  197.422852  411.472290  223.376602  535.454224   \n",
       "20637  208.689301  416.601562  195.951431  405.537598  218.852554  535.146179   \n",
       "20638  208.099899  429.433807  204.062317  418.362305  222.913101  545.697693   \n",
       "20639  210.797607  428.307312  192.335968  415.217468  217.114029  540.293518   \n",
       "\n",
       "          kp_15_y     kp_16_x     kp_16_y  label  \n",
       "0      285.743134   24.524994  281.398132    1.0  \n",
       "1      308.267334   40.383118  285.514893    1.0  \n",
       "2      308.396637   36.110382  287.430023    1.0  \n",
       "3      306.387878   33.768555  285.480804    1.0  \n",
       "4      309.895935   34.773468  284.468719    1.0  \n",
       "...           ...         ...         ...    ...  \n",
       "20635  200.456619   84.838776  201.392670    NaN  \n",
       "20636  206.514099  528.744141  229.306793    NaN  \n",
       "20637  211.927536  527.344360  230.922729    NaN  \n",
       "20638  217.271606  531.541016  228.716782    NaN  \n",
       "20639  207.061066  530.577271  228.462601    NaN  \n",
       "\n",
       "[20640 rows x 37 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b1d4ccf-97b8-428c-907b-061f48a635ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Load CSV\n",
    "df = pd.read_csv(r\"C:/Users/Kassimi/OneDrive/Bureau/cv_data/pushups\\pushup_pose_datav0.csv\")\n",
    "\n",
    "# Convert label to numeric\n",
    "df['label'] = df['label'].map({'correct sequence': 1, 'wrong sequence': 0})\n",
    "\n",
    "# Parameters\n",
    "sequence_length = 30  # Choose fixed sequence length\n",
    "min_frames_required = sequence_length\n",
    "\n",
    "# Normalize keypoints\n",
    "keypoint_cols = [col for col in df.columns if col.startswith('kp_')]\n",
    "scaler = StandardScaler()\n",
    "df[keypoint_cols] = scaler.fit_transform(df[keypoint_cols])\n",
    "\n",
    "# Group by video and build sequences\n",
    "X_sequences = []\n",
    "y_labels = []\n",
    "for video_id, group in df.groupby('video_id'):\n",
    "    group = group.sort_values('frame')\n",
    "    keypoints = group[keypoint_cols].values  # shape: (num_frames, 34)\n",
    "    label = group['label'].iloc[0]\n",
    "    \n",
    "    # Skip short sequences\n",
    "    if len(keypoints) < min_frames_required:\n",
    "        continue\n",
    "    \n",
    "    # Break long videos into multiple sequences\n",
    "    for start in range(0, len(keypoints) - sequence_length + 1, sequence_length):\n",
    "        seq = keypoints[start:start + sequence_length]\n",
    "        X_sequences.append(seq)\n",
    "        y_labels.append(label)\n",
    "\n",
    "# Convert to tensors\n",
    "X_tensor = torch.tensor(np.array(X_sequences), dtype=torch.float32)  # shape: (N, seq_len, 34)\n",
    "y_tensor = torch.tensor(y_labels, dtype=torch.long)\n",
    "\n",
    "# Train/val split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_tensor, y_tensor, test_size=0.2, random_state=42)\n",
    "\n",
    "# PyTorch Dataset\n",
    "class PushupSequenceDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# Dataloaders\n",
    "train_dataset = PushupSequenceDataset(X_train, y_train)\n",
    "val_dataset = PushupSequenceDataset(X_val, y_val)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4415e151-74bd-4fcc-9577-db14fe9e4d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PushupLSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PushupLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=34, hidden_size=64, num_layers=1, batch_first=True)\n",
    "        self.fc1 = nn.Linear(64, 32)  # LSTM output to hidden layer\n",
    "        self.fc2 = nn.Linear(32, 2)   # Hidden layer to output (2 units for binary classification)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, sequence_length, 34)\n",
    "        lstm_out, _ = self.lstm(x)              # Output shape: (batch_size, sequence_length, hidden_size)\n",
    "        x = lstm_out[:, -1, :]                  # Take output from the last time step\n",
    "        x = self.relu(self.fc1(x))              # Pass through FC layer\n",
    "        x = self.fc2(x)                         # Output layer (2 values for binary classification)\n",
    "        return x                                # Return raw logits for CrossEntropyLoss\n",
    "\n",
    "# Initialize the model\n",
    "model = PushupLSTM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9374d71e-142d-4ce6-b694-d6ca743b418e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50] Train Loss: 0.6623, Train Acc: 0.5750 | Val Loss: 0.6382, Val Acc: 0.5833\n",
      "Epoch [2/50] Train Loss: 0.6186, Train Acc: 0.6250 | Val Loss: 0.5898, Val Acc: 0.7667\n",
      "Epoch [3/50] Train Loss: 0.5635, Train Acc: 0.7292 | Val Loss: 0.5213, Val Acc: 0.7167\n",
      "Epoch [4/50] Train Loss: 0.4976, Train Acc: 0.7500 | Val Loss: 0.4647, Val Acc: 0.7167\n",
      "Epoch [5/50] Train Loss: 0.4478, Train Acc: 0.7625 | Val Loss: 0.4417, Val Acc: 0.7167\n",
      "Epoch [6/50] Train Loss: 0.4133, Train Acc: 0.7750 | Val Loss: 0.4359, Val Acc: 0.7167\n",
      "Epoch [7/50] Train Loss: 0.3806, Train Acc: 0.8042 | Val Loss: 0.4172, Val Acc: 0.7333\n",
      "Epoch [8/50] Train Loss: 0.3526, Train Acc: 0.8208 | Val Loss: 0.4032, Val Acc: 0.7500\n",
      "Epoch [9/50] Train Loss: 0.3202, Train Acc: 0.8333 | Val Loss: 0.3803, Val Acc: 0.7500\n",
      "Epoch [10/50] Train Loss: 0.2992, Train Acc: 0.8583 | Val Loss: 0.3573, Val Acc: 0.7667\n",
      "Epoch [11/50] Train Loss: 0.2691, Train Acc: 0.8875 | Val Loss: 0.3349, Val Acc: 0.7667\n",
      "Epoch [12/50] Train Loss: 0.2367, Train Acc: 0.8833 | Val Loss: 0.3109, Val Acc: 0.7833\n",
      "Epoch [13/50] Train Loss: 0.1950, Train Acc: 0.9042 | Val Loss: 0.3079, Val Acc: 0.8000\n",
      "Epoch [14/50] Train Loss: 0.1613, Train Acc: 0.9292 | Val Loss: 0.2833, Val Acc: 0.8167\n",
      "Epoch [15/50] Train Loss: 0.1662, Train Acc: 0.9333 | Val Loss: 0.3079, Val Acc: 0.8167\n",
      "Epoch [16/50] Train Loss: 0.3181, Train Acc: 0.8583 | Val Loss: 0.3880, Val Acc: 0.8000\n",
      "Epoch [17/50] Train Loss: 0.2651, Train Acc: 0.9000 | Val Loss: 0.3006, Val Acc: 0.8667\n",
      "Epoch [18/50] Train Loss: 0.2215, Train Acc: 0.9042 | Val Loss: 0.2167, Val Acc: 0.8833\n",
      "Epoch [19/50] Train Loss: 0.1910, Train Acc: 0.9208 | Val Loss: 0.2196, Val Acc: 0.8667\n",
      "Epoch [20/50] Train Loss: 0.1970, Train Acc: 0.9167 | Val Loss: 0.2213, Val Acc: 0.9000\n",
      "Epoch [21/50] Train Loss: 0.2021, Train Acc: 0.8958 | Val Loss: 0.2788, Val Acc: 0.8833\n",
      "Epoch [22/50] Train Loss: 0.2068, Train Acc: 0.9083 | Val Loss: 0.2495, Val Acc: 0.8333\n",
      "Epoch [23/50] Train Loss: 0.1696, Train Acc: 0.9167 | Val Loss: 0.2403, Val Acc: 0.8000\n",
      "Epoch [24/50] Train Loss: 0.1599, Train Acc: 0.9292 | Val Loss: 0.2188, Val Acc: 0.8333\n",
      "Epoch [25/50] Train Loss: 0.1333, Train Acc: 0.9375 | Val Loss: 0.2195, Val Acc: 0.8333\n",
      "Epoch [26/50] Train Loss: 0.1186, Train Acc: 0.9375 | Val Loss: 0.2231, Val Acc: 0.8333\n",
      "Epoch [27/50] Train Loss: 0.1148, Train Acc: 0.9375 | Val Loss: 0.2153, Val Acc: 0.8500\n",
      "Epoch [28/50] Train Loss: 0.1106, Train Acc: 0.9417 | Val Loss: 0.2108, Val Acc: 0.8667\n",
      "Epoch [29/50] Train Loss: 0.1028, Train Acc: 0.9542 | Val Loss: 0.1992, Val Acc: 0.8667\n",
      "Epoch [30/50] Train Loss: 0.0962, Train Acc: 0.9417 | Val Loss: 0.1858, Val Acc: 0.8667\n",
      "Epoch [31/50] Train Loss: 0.0924, Train Acc: 0.9417 | Val Loss: 0.1779, Val Acc: 0.8667\n",
      "Epoch [32/50] Train Loss: 0.0822, Train Acc: 0.9667 | Val Loss: 0.1650, Val Acc: 0.8833\n",
      "Epoch [33/50] Train Loss: 0.0759, Train Acc: 0.9750 | Val Loss: 0.1757, Val Acc: 0.9000\n",
      "Epoch [34/50] Train Loss: 0.0758, Train Acc: 0.9625 | Val Loss: 0.1508, Val Acc: 0.9000\n",
      "Epoch [35/50] Train Loss: 0.0669, Train Acc: 0.9708 | Val Loss: 0.1873, Val Acc: 0.9333\n",
      "Epoch [36/50] Train Loss: 0.1401, Train Acc: 0.9458 | Val Loss: 0.1753, Val Acc: 0.9167\n",
      "Epoch [37/50] Train Loss: 0.1100, Train Acc: 0.9542 | Val Loss: 0.1523, Val Acc: 0.9333\n",
      "Epoch [38/50] Train Loss: 0.0922, Train Acc: 0.9542 | Val Loss: 0.1584, Val Acc: 0.9167\n",
      "Epoch [39/50] Train Loss: 0.0761, Train Acc: 0.9750 | Val Loss: 0.1535, Val Acc: 0.9167\n",
      "Epoch [40/50] Train Loss: 0.0694, Train Acc: 0.9792 | Val Loss: 0.1745, Val Acc: 0.9167\n",
      "Epoch [41/50] Train Loss: 0.0681, Train Acc: 0.9708 | Val Loss: 0.1324, Val Acc: 0.9167\n",
      "Epoch [42/50] Train Loss: 0.0517, Train Acc: 0.9750 | Val Loss: 0.1136, Val Acc: 0.9333\n",
      "Epoch [43/50] Train Loss: 0.0423, Train Acc: 0.9875 | Val Loss: 0.1255, Val Acc: 0.9333\n",
      "Epoch [44/50] Train Loss: 0.0371, Train Acc: 0.9875 | Val Loss: 0.1270, Val Acc: 0.9333\n",
      "Epoch [45/50] Train Loss: 0.0330, Train Acc: 0.9875 | Val Loss: 0.1065, Val Acc: 0.9333\n",
      "Epoch [46/50] Train Loss: 0.0306, Train Acc: 0.9875 | Val Loss: 0.1292, Val Acc: 0.9333\n",
      "Epoch [47/50] Train Loss: 0.0279, Train Acc: 0.9917 | Val Loss: 0.1239, Val Acc: 0.9333\n",
      "Epoch [48/50] Train Loss: 0.0274, Train Acc: 0.9875 | Val Loss: 0.1581, Val Acc: 0.9333\n",
      "Epoch [49/50] Train Loss: 0.0243, Train Acc: 0.9875 | Val Loss: 0.1367, Val Acc: 0.9333\n",
      "Epoch [50/50] Train Loss: 0.0231, Train Acc: 0.9917 | Val Loss: 0.1162, Val Acc: 0.9167\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()  \n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)  # Shape: (batch_size, 2)\n",
    "        \n",
    "        # Now calculate the loss - no need for shape adjustment\n",
    "        loss = criterion(outputs, labels)  # labels should be of shape [batch_size]\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        _, predicted = torch.max(outputs, 1)  # Get the index of the maximum logit for prediction\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    avg_train_loss = train_loss / total\n",
    "    train_acc = correct / total\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    avg_val_loss = val_loss / total\n",
    "    val_acc = correct / total\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] \"\n",
    "          f\"Train Loss: {avg_train_loss:.4f}, Train Acc: {train_acc:.4f} | \"\n",
    "          f\"Val Loss: {avg_val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'pushup_classifier.pth')\n",
    "\n",
    "# Example of how to use the model for inference\n",
    "def predict_sequence(model, sequence):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        sequence = sequence.to(device)\n",
    "        output = model(sequence)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        return predicted.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1303bdc4-265a-4385-a33b-d8ac0ba3e78d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model saved to C:\\Users\\Kassimi\\OneDrive\\Bureau\\cv_data\\augmented_pushup_lstm_modelv1.pth\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model\n",
    "model_path = r\"C:\\Users\\Kassimi\\OneDrive\\Bureau\\cv_data\\augmented_pushup_lstm_modelv1.pth\"\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print(f\"âœ… Model saved to {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "578af7fb-cf29-40ca-86e1-19ef5aa3c36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully fit scaler on 10320 rows with 34 keypoint features\n",
      "YOLO pose model loaded successfully\n",
      "Video loaded successfully. Starting prediction...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing frame 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing frame 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing frame 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing frame 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing frame 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing frame 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing frame 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing frame 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing frame 90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing frame 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing frame 110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing frame 120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing frame 130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing frame 140\n",
      "Prediction completed. Video saved as 'pushup_prediction2.mp4'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kassimi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import deque\n",
    "\n",
    "# Define LSTM model class (needs to match what you used in training)\n",
    "class PushupLSTM(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PushupLSTM, self).__init__()\n",
    "        self.lstm = torch.nn.LSTM(input_size=34, hidden_size=64, num_layers=1, batch_first=True)\n",
    "        self.fc1 = torch.nn.Linear(64, 32)\n",
    "        self.fc2 = torch.nn.Linear(32, 2)  # 2 outputs for binary classification\n",
    "        self.relu = torch.nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        x = lstm_out[:, -1, :]  # Take output from the last time step\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# LSTM sequence length (must match training)\n",
    "sequence_length = 30\n",
    "\n",
    "# Load trained model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_path = r'C:\\Users\\Kassimi\\OneDrive\\Bureau\\cv_data\\augmented_pushup_lstm_modelv1.pth'\n",
    "model = PushupLSTM()\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Load scaler (refit on original dataset)\n",
    "try:\n",
    "    df = pd.read_csv(r\"C:\\Users\\Kassimi\\OneDrive\\Bureau\\cv_data\\pushups\\pushup_pose_datav0.csv\")\n",
    "    # Only use keypoint columns that contain numerical data\n",
    "    keypoint_cols = [col for col in df.columns if col.startswith('kp_')]\n",
    "    \n",
    "    # Make sure we only use numeric data for scaling\n",
    "    # First check if the data is clean\n",
    "    for col in keypoint_cols:\n",
    "        if df[col].dtype == 'object':\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    \n",
    "    # Drop rows with NaN values that might have been created by coercion\n",
    "    df = df.dropna(subset=keypoint_cols)\n",
    "    \n",
    "    # Now fit the scaler\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(df[keypoint_cols])\n",
    "    print(f\"Successfully fit scaler on {len(df)} rows with {len(keypoint_cols)} keypoint features\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error fitting scaler: {e}\")\n",
    "    print(\"Will continue with default scaling instead\")\n",
    "    # If loading fails, we'll use a simple normalization as fallback\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "# Load YOLO pose model\n",
    "try:\n",
    "    yolo_model = YOLO('yolov8n-pose.pt')\n",
    "    print(\"YOLO pose model loaded successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading YOLO model: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# Video path\n",
    "video_path = r\"D:\\Kassimi\\Pictures\\Camera Roll\\WIN_20250505_09_38_56_Pro.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "if not cap.isOpened():\n",
    "    print(f\"Error: Could not open video {video_path}\")\n",
    "    exit(1)\n",
    "\n",
    "print(f\"Video loaded successfully. Starting prediction...\")\n",
    "\n",
    "# Buffer to store sequence of keypoints\n",
    "sequence_buffer = deque(maxlen=sequence_length)\n",
    "\n",
    "# For video output\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "out = cv2.VideoWriter('pushup_prediction3.mp4', cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))\n",
    "\n",
    "frame_count = 0\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "        \n",
    "    frame_count += 1\n",
    "    if frame_count % 10 == 0:\n",
    "        print(f\"Processing frame {frame_count}\")\n",
    "    \n",
    "    # Get YOLO pose estimation\n",
    "    results = yolo_model.predict(frame, save=False, verbose=False)\n",
    "    \n",
    "    # Draw the pose on the frame (optional)\n",
    "    annotated_frame = results[0].plot()\n",
    "    \n",
    "    # Check if any person was detected\n",
    "    keypoints = results[0].keypoints.xy.cpu().numpy()\n",
    "    \n",
    "    if len(keypoints) > 0:  # If at least one person is detected\n",
    "        # Take the first person's keypoints\n",
    "        person_keypoints = keypoints[0].flatten()\n",
    "        \n",
    "        # Make sure we have the right number of keypoints\n",
    "        if len(person_keypoints) == 34:  # 17 keypoints * 2 (x,y)\n",
    "            try:\n",
    "                # Scale keypoints using our scaler\n",
    "                if hasattr(scaler, 'mean_'):  # Check if scaler was properly fitted\n",
    "                    person_keypoints_scaled = scaler.transform([person_keypoints])[0]\n",
    "                else:\n",
    "                    # Simple normalization as fallback\n",
    "                    person_keypoints_scaled = (person_keypoints - np.mean(person_keypoints)) / (np.std(person_keypoints) + 1e-8)\n",
    "                \n",
    "                # Add to sequence buffer\n",
    "                sequence_buffer.append(person_keypoints_scaled)\n",
    "                \n",
    "                # Only predict when we have a full sequence\n",
    "                if len(sequence_buffer) == sequence_length:\n",
    "                    input_seq = torch.tensor([list(sequence_buffer)], dtype=torch.float32).to(device)\n",
    "                    \n",
    "                    with torch.no_grad():\n",
    "                        output = model(input_seq)\n",
    "                        probabilities = torch.softmax(output, dim=1)\n",
    "                        confidence, predicted_class = torch.max(probabilities, 1)\n",
    "                    \n",
    "                    # Get the prediction and confidence\n",
    "                    label = 'Correct Form' if predicted_class.item() == 1 else 'Incorrect Form'\n",
    "                    conf_value = confidence.item()\n",
    "                    \n",
    "                    # Set color based on prediction (green for correct, red for incorrect)\n",
    "                    color = (0, 255, 0) if label == 'Correct Form' else (0, 0, 255)\n",
    "                    \n",
    "                    # Display prediction on frame\n",
    "                    cv2.putText(annotated_frame, f\"{label} ({conf_value:.2f})\", \n",
    "                                (30, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.0, color, 2)\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error in prediction: {e}\")\n",
    "    \n",
    "    # Display frame with predictions\n",
    "    cv2.imshow('Pushup Form Prediction', annotated_frame)\n",
    "    out.write(annotated_frame)\n",
    "    \n",
    "    # Break loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"Prediction completed. Video saved as 'pushup_prediction2.mp4'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5264be01-f65e-4ec7-9711-7497cdbcce83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "LSTM model loaded successfully\n",
      "Using default scaler (make sure your keypoint values are properly scaled)\n",
      "YOLO pose model loaded successfully\n",
      "Webcam initialized. Starting live prediction...\n",
      "Press 'q' to quit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kassimi\\AppData\\Local\\Temp\\ipykernel_1708\\3123729608.py:126: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:257.)\n",
      "  input_seq = torch.tensor([list(sequence_buffer)], dtype=torch.float32).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Application closed\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import deque\n",
    "import time\n",
    "\n",
    "# Define LSTM model class (same as your original)\n",
    "class PushupLSTM(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PushupLSTM, self).__init__()\n",
    "        self.lstm = torch.nn.LSTM(input_size=34, hidden_size=64, num_layers=1, batch_first=True)\n",
    "        self.fc1 = torch.nn.Linear(64, 32)\n",
    "        self.fc2 = torch.nn.Linear(32, 2)  # 2 outputs for binary classification\n",
    "        self.relu = torch.nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        x = lstm_out[:, -1, :]  # Take output from the last time step\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# LSTM sequence length (must match training)\n",
    "sequence_length = 30\n",
    "\n",
    "# Load trained model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Update the path to your model\n",
    "model_path = r'C:\\Users\\Kassimi\\OneDrive\\Bureau\\cv_data\\augmented_pushup_lstm_modelv1.pth'\n",
    "model = PushupLSTM()\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "print(\"LSTM model loaded successfully\")\n",
    "\n",
    "# Create a simple scaler as fallback since we might not have access to the original dataset\n",
    "scaler = StandardScaler()\n",
    "print(\"Using default scaler (make sure your keypoint values are properly scaled)\")\n",
    "\n",
    "# Load YOLO pose model\n",
    "try:\n",
    "    yolo_model = YOLO('yolov8n-pose.pt')\n",
    "    print(\"YOLO pose model loaded successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading YOLO model: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# Initialize webcam\n",
    "cap = cv2.VideoCapture(0)  # 0 is usually the default webcam\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open webcam\")\n",
    "    exit(1)\n",
    "\n",
    "# Set webcam resolution (optional)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "\n",
    "print(\"Webcam initialized. Starting live prediction...\")\n",
    "print(\"Press 'q' to quit\")\n",
    "\n",
    "# Buffer to store sequence of keypoints\n",
    "sequence_buffer = deque(maxlen=sequence_length)\n",
    "\n",
    "# Variable to track prediction status\n",
    "prediction_ready = False\n",
    "last_prediction = \"Waiting for enough frames...\"\n",
    "confidence = 0.0\n",
    "color = (255, 255, 0)  # Yellow for waiting\n",
    "\n",
    "# For FPS calculation\n",
    "prev_time = time.time()\n",
    "fps = 0\n",
    "\n",
    "# Flag to toggle recording\n",
    "is_recording = False\n",
    "out = None\n",
    "\n",
    "# Counter for pushups\n",
    "pushup_count = 0\n",
    "last_state = None\n",
    "pushup_threshold = 0.7  # Confidence threshold for counting\n",
    "\n",
    "frame_count = 0\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to grab frame from webcam\")\n",
    "        break\n",
    "    \n",
    "    # Calculate FPS\n",
    "    current_time = time.time()\n",
    "    fps = 1 / (current_time - prev_time)\n",
    "    prev_time = current_time\n",
    "    \n",
    "    # Process every frame\n",
    "    frame_count += 1\n",
    "    \n",
    "    # Get YOLO pose estimation\n",
    "    results = yolo_model.predict(frame, save=False, verbose=False)\n",
    "    \n",
    "    # Draw the pose on the frame\n",
    "    annotated_frame = results[0].plot()\n",
    "    \n",
    "    # Check if any person was detected\n",
    "    keypoints = results[0].keypoints.xy.cpu().numpy()\n",
    "    \n",
    "    if len(keypoints) > 0:  # If at least one person is detected\n",
    "        # Take the first person's keypoints\n",
    "        person_keypoints = keypoints[0].flatten()\n",
    "        \n",
    "        # Make sure we have the right number of keypoints\n",
    "        if len(person_keypoints) == 34:  # 17 keypoints * 2 (x,y)\n",
    "            try:\n",
    "                # Simple normalization as we don't have the original scaler\n",
    "                person_keypoints_scaled = (person_keypoints - np.mean(person_keypoints)) / (np.std(person_keypoints) + 1e-8)\n",
    "                \n",
    "                # Add to sequence buffer\n",
    "                sequence_buffer.append(person_keypoints_scaled)\n",
    "                \n",
    "                # Only predict when we have a full sequence\n",
    "                if len(sequence_buffer) == sequence_length:\n",
    "                    input_seq = torch.tensor([list(sequence_buffer)], dtype=torch.float32).to(device)\n",
    "                    \n",
    "                    with torch.no_grad():\n",
    "                        output = model(input_seq)\n",
    "                        probabilities = torch.softmax(output, dim=1)\n",
    "                        confidence_tensor, predicted_class = torch.max(probabilities, 1)\n",
    "                    \n",
    "                    # Get the prediction and confidence\n",
    "                    prediction_ready = True\n",
    "                    last_prediction = 'Correct Form' if predicted_class.item() == 1 else 'Incorrect Form'\n",
    "                    confidence = confidence_tensor.item()\n",
    "                    \n",
    "                    # Set color based on prediction\n",
    "                    color = (0, 255, 0) if last_prediction == 'Correct Form' else (0, 0, 255)\n",
    "                    \n",
    "                    # Simple pushup counter logic\n",
    "                    current_state = 'up' if confidence > pushup_threshold and last_prediction == 'Correct Form' else 'down'\n",
    "                    if last_state == 'down' and current_state == 'up':\n",
    "                        pushup_count += 1\n",
    "                    last_state = current_state\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error in prediction: {e}\")\n",
    "    \n",
    "    # Display prediction on frame\n",
    "    if prediction_ready:\n",
    "        cv2.putText(annotated_frame, f\"{last_prediction} ({confidence:.2f})\", \n",
    "                    (30, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.0, color, 2)\n",
    "    else:\n",
    "        cv2.putText(annotated_frame, last_prediction, \n",
    "                    (30, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.0, color, 2)\n",
    "    \n",
    "    # Display pushup counter\n",
    "    cv2.putText(annotated_frame, f\"Pushup Count: {pushup_count}\", \n",
    "                (30, 90), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255, 165, 0), 2)\n",
    "    \n",
    "    # Display FPS\n",
    "    cv2.putText(annotated_frame, f\"FPS: {fps:.1f}\", \n",
    "                (frame.shape[1] - 150, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "    \n",
    "    # Display recording status if recording\n",
    "    if is_recording:\n",
    "        cv2.putText(annotated_frame, \"REC\", \n",
    "                    (frame.shape[1] - 70, 70), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "        # Record frame if we're recording\n",
    "        out.write(annotated_frame)\n",
    "    \n",
    "    # Display frame with predictions\n",
    "    cv2.imshow('Pushup Form Detection (Webcam)', annotated_frame)\n",
    "    \n",
    "    # Check for key presses\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    \n",
    "    # Quit if 'q' is pressed\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    \n",
    "    # Toggle recording if 'r' is pressed\n",
    "    elif key == ord('r'):\n",
    "        is_recording = not is_recording\n",
    "        if is_recording:\n",
    "            # Initialize video writer\n",
    "            fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "            timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "            out = cv2.VideoWriter(f'pushup_webcam_{timestamp}.mp4', \n",
    "                                 fourcc, 20.0, \n",
    "                                 (frame.shape[1], frame.shape[0]))\n",
    "            print(\"Recording started\")\n",
    "        else:\n",
    "            if out is not None:\n",
    "                out.release()\n",
    "                print(\"Recording stopped and saved\")\n",
    "    \n",
    "    # Reset pushup counter if 'c' is pressed\n",
    "    elif key == ord('c'):\n",
    "        pushup_count = 0\n",
    "        print(\"Pushup counter reset\")\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "if out is not None:\n",
    "    out.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"Application closed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

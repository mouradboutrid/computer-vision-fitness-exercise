{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0tf6a8qltjw3"
      },
      "outputs": [],
      "source": [
        "!pip install protobuf==3.20.3 mediapipe==0.10.9"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "import mediapipe as mp\n",
        "\n",
        "\n",
        "# Define body part landmark groups (based on MediaPipe's 33 landmarks)\n",
        "LANDMARK_GROUPS = {\n",
        "    'arms': [11, 12, 13, 14, 15, 16],         # Shoulders to wrists\n",
        "    'legs': [23, 24, 25, 26, 27, 28],         # Hips to ankles\n",
        "    'core': [23, 24, 11, 12],                 # Hips and shoulders\n",
        "    'upper_body': list(range(11)) + list(range(11, 17))  # Above hips\n",
        "}\n",
        "\n",
        "# Define exercise-specific landmark weighting (based on muscle involvement)\n",
        "EXERCISE_WEIGHTS = {\n",
        "    'bench press': {'arms': 0.5, 'core': 0.3, 'legs': 0.2},\n",
        "    'barbell biceps curl': {'arms': 0.7, 'core': 0.2, 'legs': 0.1},\n",
        "    'chest fly machine': {'arms': 0.5, 'core': 0.4, 'legs': 0.1},\n",
        "    'deadlift': {'legs': 0.4, 'core': 0.4, 'arms': 0.2},\n",
        "    'decline bench press': {'arms': 0.5, 'core': 0.3, 'legs': 0.2},\n",
        "    'hammer curl': {'arms': 0.7, 'core': 0.2, 'legs': 0.1},\n",
        "    'hip thrust': {'legs': 0.5, 'core': 0.4, 'arms': 0.1},\n",
        "    'incline bench press': {'arms': 0.5, 'core': 0.3, 'legs': 0.2},\n",
        "    'lat pulldown': {'arms': 0.5, 'core': 0.4, 'legs': 0.1},\n",
        "    'lateral raise': {'arms': 0.6, 'core': 0.3, 'legs': 0.1},\n",
        "    'leg extension': {'legs': 0.7, 'core': 0.2, 'arms': 0.1},\n",
        "    'leg raises': {'core': 0.6, 'legs': 0.3, 'arms': 0.1},\n",
        "    'plank': {'core': 0.7, 'arms': 0.2, 'legs': 0.1},\n",
        "    'pull Up': {'arms': 0.5, 'core': 0.4, 'legs': 0.1},\n",
        "    'push-up': {'arms': 0.5, 'core': 0.4, 'legs': 0.1},\n",
        "    'romanian deadlift': {'legs': 0.5, 'core': 0.3, 'arms': 0.2},\n",
        "    'russian twist': {'core': 0.6, 'arms': 0.2, 'legs': 0.2},\n",
        "    'shoulder press': {'arms': 0.6, 'core': 0.3, 'legs': 0.1},\n",
        "    'squat': {'legs': 0.6, 'core': 0.3, 'arms': 0.1},\n",
        "    't bar row': {'arms': 0.4, 'core': 0.4, 'legs': 0.2},\n",
        "    'tricep dips': {'arms': 0.6, 'core': 0.3, 'legs': 0.1},\n",
        "    'tricep Pushdown': {'arms': 0.7, 'core': 0.2, 'legs': 0.1}\n",
        "}\n",
        "\n",
        "# Initialize MediaPipe Pose Model\n",
        "mp_pose = mp.solutions.pose\n",
        "pose = mp_pose.Pose(\n",
        "    static_image_mode=False,\n",
        "    model_complexity=2,  # More accurate model\n",
        "    min_detection_confidence=0.5\n",
        ")\n",
        "\n",
        "def calculate_weighted_confidence(landmarks, exercise_type):\n",
        "    \"\"\"Calculates visibility-weighted confidence per landmark\"\"\"\n",
        "    weights = EXERCISE_WEIGHTS[exercise_type]\n",
        "    weighted_scores = np.zeros(33)\n",
        "    for group, weight in weights.items():\n",
        "        for lm_idx in LANDMARK_GROUPS[group]:\n",
        "            weighted_scores[lm_idx] = landmarks[lm_idx].visibility * weight\n",
        "    return weighted_scores\n",
        "\n",
        "def normalize_poses(poses):\n",
        "    \"\"\"Centers poses around the hip midpoint\"\"\"\n",
        "    normalized_poses = []\n",
        "    for pose in poses:\n",
        "        landmarks = pose.reshape(-1, 4)\n",
        "        left_hip = landmarks[23][:3]\n",
        "        right_hip = landmarks[24][:3]\n",
        "        hip_center = (left_hip + right_hip) / 2\n",
        "        normalized_landmarks = landmarks.copy()\n",
        "        normalized_landmarks[:, :3] -= hip_center\n",
        "        normalized_poses.append(normalized_landmarks.flatten())\n",
        "    return np.array(normalized_poses)\n",
        "\n",
        "def calculate_velocity(poses):\n",
        "    \"\"\"Computes frame-to-frame velocity of poses\"\"\"\n",
        "    velocity = np.zeros_like(poses)\n",
        "    velocity[1:] = poses[1:] - poses[:-1]\n",
        "    return velocity\n",
        "\n",
        "def extract_poses_from_video(video_path, exercise_type, max_frames=45):\n",
        "    \"\"\"Processes a single video and extracts pose + velocity + confidence\"\"\"\n",
        "    poses, confidence_scores, weighted_confidences = [], [], []\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "        raise ValueError(f\"Failed to open: {video_path}\")\n",
        "\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    frame_indices = np.linspace(0, total_frames-1, max_frames, dtype=int)\n",
        "\n",
        "    for frame_idx in frame_indices:\n",
        "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        frame = cv2.resize(frame, (640, 480))\n",
        "        results = pose.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "        if results.pose_landmarks:\n",
        "            confidence = np.mean([lm.visibility for lm in results.pose_landmarks.landmark])\n",
        "            weighted_conf = calculate_weighted_confidence(results.pose_landmarks.landmark, exercise_type)\n",
        "            if confidence > 0.4:\n",
        "                lm_array = np.array([[lm.x, lm.y, lm.z, lm.visibility] for lm in results.pose_landmarks.landmark])\n",
        "                poses.append(lm_array.flatten())\n",
        "                confidence_scores.append(confidence)\n",
        "                weighted_confidences.append(weighted_conf)\n",
        "                continue\n",
        "\n",
        "        # Fallback for low confidence or missing pose\n",
        "        poses.append(np.zeros(33 * 4))\n",
        "        confidence_scores.append(0.0)\n",
        "        weighted_confidences.append(np.zeros(33))\n",
        "\n",
        "    cap.release()\n",
        "\n",
        "    # Pad if not enough frames\n",
        "    while len(poses) < max_frames:\n",
        "        poses.append(poses[-1])\n",
        "        confidence_scores.append(0.0)\n",
        "        weighted_confidences.append(weighted_confidences[-1])\n",
        "\n",
        "    poses = np.array(poses)\n",
        "    normalized = normalize_poses(poses)\n",
        "    velocity = calculate_velocity(normalized)\n",
        "    weighted_conf = np.array(weighted_confidences)\n",
        "    final = np.concatenate([normalized, velocity, weighted_conf], axis=1)\n",
        "    return final, np.array(confidence_scores)\n",
        "\n",
        "def mirror_augment(poses):\n",
        "    \"\"\"Creates horizontally mirrored version of pose sequence\"\"\"\n",
        "    mirrored = poses.copy()\n",
        "    pose_part = mirrored[:, :33*4].reshape(-1, 33, 4)\n",
        "    velocity = mirrored[:, 33*4:33*8].reshape(-1, 33, 4)\n",
        "    weighted_conf = mirrored[:, 33*8:]\n",
        "\n",
        "    # Mirror X coords\n",
        "    pose_part[:, :, 0] = 1 - pose_part[:, :, 0]\n",
        "    velocity[:, :, 0] *= -1\n",
        "\n",
        "    # Swap left-right pairs\n",
        "    pairs = [(1,2), (3,4), (5,6), (7,8), (9,10), (11,12), (13,14), (15,16),\n",
        "             (23,24), (25,26), (27,28), (29,30), (31,32)]\n",
        "    for i, j in pairs:\n",
        "        pose_part[:, [i, j]] = pose_part[:, [j, i]]\n",
        "        velocity[:, [i, j]] = velocity[:, [j, i]]\n",
        "        weighted_conf[:, [i, j]] = weighted_conf[:, [j, i]]\n",
        "\n",
        "    return np.concatenate([pose_part.reshape(poses.shape[0], -1),\n",
        "                           velocity.reshape(poses.shape[0], -1),\n",
        "                           weighted_conf], axis=1)\n",
        "\n",
        "def prepare_and_save_dataset(base_folder, target_classes, save_dir, max_frames=45):\n",
        "    \"\"\"Processes the dataset, applies augmentation, saves as .npy\"\"\"\n",
        "    X, y, confidences = [], [], []\n",
        "    class_mapping = {}\n",
        "    skipped_videos = defaultdict(int)\n",
        "\n",
        "    print(\"Preparing dataset...\")\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    for root, _, files in os.walk(base_folder):\n",
        "        class_name = os.path.basename(root)\n",
        "        if class_name not in target_classes:\n",
        "            continue\n",
        "        if class_name not in class_mapping:\n",
        "            class_mapping[class_name] = len(class_mapping)\n",
        "\n",
        "        for file in files:\n",
        "            if file.lower().endswith(('.mp4', '.avi', '.mov')):  # Check video formats\n",
        "                try:\n",
        "                    video_path = os.path.join(root, file)\n",
        "                    poses, conf = extract_poses_from_video(video_path, class_name, max_frames)\n",
        "\n",
        "                    if np.mean(conf) > 0.2:\n",
        "                        X.append(poses)\n",
        "                        y.append(class_mapping[class_name])\n",
        "                        confidences.append(np.mean(conf))\n",
        "\n",
        "                        X.append(mirror_augment(poses))\n",
        "                        y.append(class_mapping[class_name])\n",
        "                        confidences.append(np.mean(conf))\n",
        "                    else:\n",
        "                        skipped_videos[class_name] += 1\n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing {file}: {e}\")\n",
        "                    skipped_videos[class_name] += 1\n",
        "\n",
        "    # Convert and save\n",
        "    X, y, confidences = np.array(X), np.array(y), np.array(confidences)\n",
        "    np.save(os.path.join(save_dir, 'X.npy'), X)\n",
        "    np.save(os.path.join(save_dir, 'y.npy'), y)\n",
        "    np.save(os.path.join(save_dir, 'confidences.npy'), confidences)\n",
        "    np.save(os.path.join(save_dir, 'class_mapping.npy'), class_mapping)\n",
        "\n",
        "    print(f\"\\nSaved to {save_dir}\")\n",
        "    print(f\"X shape: {X.shape}\")\n",
        "    for name, idx in class_mapping.items():\n",
        "        print(f\"{name}: {(y == idx).sum()} samples\")\n",
        "    return X, y, class_mapping, confidences\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    base_folder = \"/content/drive/MyDrive/CVP/CV_PData\"  # Folder with subfolders for each class\n",
        "    save_dir = \"/content/drive/MyDrive/CVP/processed_landmark_data\"\n",
        "    target_classes = list(EXERCISE_WEIGHTS.keys())  # all 22 exercise names\n",
        "\n",
        "    X, y, class_mapping, confidences = prepare_and_save_dataset(base_folder, target_classes, save_dir)"
      ],
      "metadata": {
        "id": "0r687QCytrqU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}